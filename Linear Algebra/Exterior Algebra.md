Given $V$ an $F$-[[Vector Space]] where $F$ is a [[Field]], with the two-sided [[Ideal]] $I=\paren{\set{v\otimes v:v\in V}}$, the **exterior algebra** is defined as as the quotient [[Algebra]] of the [[Tensor]] algebra $$\Lambda  V=T(V)/I,\quad\ v\wedge w\equiv v\otimes w\pmod{I}$$which is an $F$-algebra with summation and **wedge product**. In terms of universal property, for any associative $F$-algebra $A$ and an $F$-linear map $j$ with $\paren{j(v)}^2=0,\forall v\in V$, there exists a unique algebra homomorphism $f$ inducing the commutative diagram
<p align="center"><img align="center" src="https://i.upmath.me/svg/%0A%5Cbegin%7Btikzcd%7D%0AV%20%5Carrow%5Br%2C%20%22%5Ciota%22%5D%20%5Carrow%5Brd%2C%20%22j%22'%5D%20%26%20%5CLambda%20V%20%5Carrow%5Bd%2C%20%22f%22%2C%20dashed%5D%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%5Cend%7Btikzcd%7D%0A"/></p>
Elements in $\Lambda^k V$ are referred to as **$k$-vectors**. Note that we're using $\Lambda$ instead of $\bigwedge$ simply for better appearance. We'll denote $v_{i_1}\wedge\cdots\wedge v_{i_k}= v^{\wedge I},I=(i_1,\cdots,i_k)$ for convenience. 
- **Motivation**: exterior algebra rises natural under the desire to model multilinear functions. It's a formal framework within which we can discuss concrete objects like symmetric/alternating functions.
	- **Interpretation under UP**: the UP of exterior algebra says that any alternating map from $V$ to an associative algebra must factor through $\Lambda V$, hence it serves as a detector for redundancy of linear dependence. 
	- **Source of name**: the name of "exterior" was original termed by Grassmann to reflect the fact that $x\wedge y\neq0$ iff $y$ lies outsides (in the exterior of) $\span(x)$. This was to be contrasted to the interior (inner) product introduced for [[Euclidean Vector]], which is nonzero only when $y$ contains nonzero component in $\span(x)$. 
- **Graded algebra structure**: by definition, both $T(V)$ and $$\Lambda V=\bigoplus_{k\in\mathbb N}\Lambda^kV$$are $\mathbb N$-graded [[Algebra]] formed by direct sum ([[Module]]). 
- **Exterior power of operator**: given $T\in\End(V)$ we define $$\Lambda^kT:\Lambda^kV\to\Lambda^kV,\quad v_1\wedge\cdots\wedge v_k\mapsto T( v_1)\wedge\cdots\wedge T(v_k)$$This is called the exterior power of $T$. 
- **Symmetric algebra**: we could choose to take quotient by another ideal $$S(V)=T(V)/I\where I=\paren{\set{(v\otimes w-w\otimes v):v,w\in V}}$$Then $S(V)$ is called the **symmetric algebra** over $V$. We have the intuitive correspondence $$\begin{array}{c}\text{Tensor Algebra }T(V)&\longleftrightarrow&\text{Permutation}\\\text{Exterior Algebra }\Lambda (V)&\longleftrightarrow&\text{Combination with Orientation}\\\text{Symmetric Algebra }S(V)&\longleftrightarrow&\text{Combination}\end{array}$$This correspondence is also reflected by that between their dimensions and [[Combination & Permutation]]. 
## Properties
- **Arithmetic properties**
	- **Anti-commutativity**: by definition we have $$(v+w)\wedge(v+w)=0\imply v\wedge w=-w\wedge v$$Hence wedge product is anti-commutative. 
		- **Rearrangement**: by repetitive application of anti-commutativity we deduce that $$v_{\sigma(1)}\wedge\cdots\wedge v_{\sigma(k)}=\sgn\sigma\cdot v_1\wedge\cdots\wedge v_k$$Therefore a repetitive term in a wedge product implies that the wedge product is $0$. 
	- **Associativity**: by associativity of tensor product we have $$(u\wedge v)\wedge w=u\wedge( v\wedge w)$$
- **Linear dependence verification**: given vectors $v_1,\cdots v_k$ we have $$v^{\wedge[k]}=0\qiffq \set{v_i}_{1\le i\le k}\text{ is linearly dependent}$$**Proof**: $(\Leftarrow)$ is straightforward by linear decomposition and definition; for $(\Rightarrow)$, assume that $\set{v_i}_{1\le i\le k}$ is linearly independent, then by AoC ([[Set]]) we can extend it to a Hamel basis ([[Vector Space]]) $\set{v_i}_{i\in I}$, and pick a dual system ([[Algebraic Dual Space]]) $$\phi^i\in V^\#\quad\st\quad \phi^i(v_j)=\delta_j^i$$Now by property of [[Determinant]] we can construct an alternating multilinear function by $$f(v_1,\cdots,v_k)=\det\paren{\phi_i(v_j)}_i^j$$By the natural isomorphism in the next section, there exists $$L\in\paren{\Lambda^kV}^\#\quad\st\quad L(v_1\wedge\cdots\wedge v_k)=f(v_1,\cdots,v_k)=1\neq0$$Therefore we must have $v_1\wedge\cdots\wedge v_k\neq0$. 
	- **Intuition**: to show that an object is nonzero, we could consider to construct a functional that "detects" it. In coordinate-free geometry, this means we don't need to know the global structure of $V$; we only need to know that the local "shadow" of the vectors in $F^k$ (via the functionals) is non-degenerate. 
- **Basis**: let $\set{e_\alpha}_{\alpha\in I}$ be a Hamel basis, then we have $$\Lambda^kV=\span_F\paren{e^{\wedge I}:I=(i_1<\cdots<i_k)}$$This can be verified directly. 
	- **Dimension**: assuming $\dim V=n<\infty$, then by the basis above we know that $$\dim\Lambda^kV=\binom{n}{k},\quad\forall0\le k\le n$$hence the total dimension is $\dim\Lambda V=2^n$ by [[Combination & Permutation]]. 
## Dual exterior algebra
The **dual exterior algebra** of $V$ is defined as the exterior algebra of [[Algebraic Dual Space]] $\bigwedge V^\#$. 
- **Natural isomorphism**: there is a natural algebra isomorphism given by pairing $$\Lambda^k V^\#\cong\paren{\Lambda^k V}^\#,\quad\braket{\alpha_1\wedge\cdots\wedge\alpha_k,v_1\wedge\cdots\wedge v_k}=\det(\alpha_i(v_j))$$which follows from definition of [[Determinant]]. That why we can essentially treat a $k$-tensor as just a $k$-linear function.
- **Basis for finite dimensional $V$**: assuming $\dim V<\infty$, and let $\set{\alpha}_{\alpha\in I}$ be the dual system of $\set{e_\alpha}_{\alpha\in I}$, then we have $$\Lambda^k V^*=\span_F\paren{\alpha^{\wedge I}:I=(i_1<\cdots<i_k)}$$Note that when $\dim V=\infty$ the situation is much more complicated, due to the discussion in [[Algebraic Dual Space]]. 
### Multilinear function
Multilinear function provides a concrete representation of elements in the dual exterior algebra. A function $f:V^k\to\mathbb R$ is **multilinear ($k$-tensor)** if it's linear in each variable. The set of $k$-tensors is denoted $L_k(V)$. Denote $$\sigma f(v_1,\cdots,v_k)=f\circ\sigma(v_1,\cdots,v_k)=f(v_{\sigma(1)},\cdots,v_{\sigma(k)}),\quad\sigma\in S_k$$then we can define **symmetric/alternating** functions by $$\begin{array}{ll}\text{Symmetric:}&f\in S_k(V)\iff\sigma f=f,&\forall\sigma\in S_k \\\text{Alternating:}&f\in A_k(V)\iff\sigma f=(\sgn\sigma) f,&\forall\sigma\in S_k\end{array}$$Here $S_k$ is the [[Symmetric Group]]. 
- **Symmetrizing/alternating operator**: define $$\sym f=\frac{1}{k!}\sum_{\sigma\in S_k}\sigma f\in S_k(V),\quad\alt f=\frac{1}{k!}\sum_{\sigma\in S_k}(\sgn\sigma)\sigma f\in A_k(V)$$Notice that if we already have $f\in S_k$ (resp. $f\in A_k$) then $\sym f=f$ (resp. $\alt f=f$).
	- **Decomposition into symmetric & alternating part**: we have $$f=\sym f+\alt f,\quad \forall f\in L_k(V)$$**Proof**: given $f\in L_k(V)$, assuming that we have the decomposition $$f=f_S+f_A\where f_S\in S_k(V),f_A\in A_k(V)$$Then by definition we have $$\sigma f=f_S+(\sgn\sigma)f_A\imply\sum_{\sigma\in S_k}\sigma f=k!f_S+0,\quad \quad \sum_{\sigma\in S_k}(\sgn\sigma)\sigma f=k!f_A$$Therefore we get $f_S=\sym f,\quad f_A=\alt f$. Alternatively, we can also proceed by directly summing $\sym f,\alt f$ and check that the identity holds, which follows from some straightforward calculation. 
- **Tensor product of covectors**: given $f\in L_k,g\in L_l$, define their tensor product as $$(f\otimes g)(v_1,\cdots,v_{k+l})=f(v_1,\cdots,v_k)g(v_{l+1},\cdots,v_{k+l})$$Obviously we have $(f\otimes g)\otimes h=f\otimes(g\otimes h)$.
- **Wedge product of covectors**: for $f\in A_k(V),g\in A_l(V)$ define their wedge product as $$f\wedge g=\alt(f\otimes g)$$or explicitly written as $$(f\wedge g)(v_1,\cdots,v_{k+l})=\frac{1}{(k+l)!}\sum_{\sigma\in S_{k+l}}(\sgn\sigma)f(v_{\sigma(1)},\cdots,v_{\sigma(k)})g(v_{\sigma(k+1)},\cdots,v_{\sigma(k+1)})$$It's obvious then that $f\wedge g\in A_{k+l}(V)$, and wedge product is linear in each argument by linearity of tensor product. 
	- **Equivalence of definition**: the purely algebraic definition for exterior algebra still applies here, and actually provides a more structural perspective on this concept. For equivalence, take for example $\alpha,\beta\in V^*$, then we have $$\alpha\wedge\beta=\alpha\otimes\beta=\frac{1}{2}(\alpha\otimes\beta-\beta\otimes\alpha)$$Notice that the alternating process is encoded in the step of taking quotient, since the resulting equivalence class consists of tensors that can be constructed via alternation of vector inputs.
	- **Arithmetic properties**: we can verifies properties like anti-commutativity and associativity directly. 
	- **Linear independence**: $\alpha_i\in V^*$ are linear independent iff $\bigwedge\alpha_i\neq0$.
	  **Proof**: for $\Leftarrow$ assume otherwise that $\sum_{i=1}^kc_i\alpha_i=0$. WLOG assume $c_1=1$, then $$\bigwedge_{i=1}^k\alpha_i=\left(\sum_{i=2}^k-c_i\alpha_i\right)\wedge\alpha_2\wedge\cdots\wedge\alpha_k=-\sum_{i=2}^kc_i\alpha_i\wedge\alpha_2\wedge\cdots\wedge\alpha_k=0$$where we used the fact $\alpha_i\wedge\alpha_i=-\alpha_i\wedge\alpha_i\Rightarrow\alpha_i\wedge\alpha_i=0$. Conversely if $\bigwedge\alpha_i=0$ and meanwhile $\alpha_i$ are linearly independent we have $\varepsilon_i=\sum_jb_{ij}\alpha_j$ where $\varepsilon_i$ are the standard dual basis ([[Algebraic Dual Space]]), and by the linear transform property below we have $\bigwedge\varepsilon_i=\det(b_{ij})_i^j\bigwedge\alpha_i=0$, a contradiction. 
- **Linear transformation**: we have that $$\beta_i=\sum_{j=1}^ka_{ij}\alpha_j\quad\Longrightarrow\quad\bigwedge_{i=1}^k\beta_i=\det(a_{ij})_i^j\bigwedge_{i=1}^k\alpha_i$$by linearity and alternating property of wedge product.
## Diagonalization of tensor
**Motivation**: in [[Matrix]] we can always transform a quadratic form $\sum a_{ij}x_ix_j$ via diagonalization of matrices, and in [[Linear PDE]] a second order PDE can also be transformed into its canonical form via the same method. It's quite tempting to generalize to $n$-th order "object", and the natural choice of such algebraic structure would be $n$-tensors.
In general consider $\xi_i$ a set of basis for, and denote $$V=\span(\xi:1\le i\le n),\quad\sigma=\sum_{|\alpha|=m}a_\alpha\xi^\alpha$$then we wanna find a proper $\xi=P\eta,P\in F^n$ that transforms the above into $$\sigma=\sum_{k=1}^n\lambda_k\eta_k^m$$A partial solution to this is the **Waring decomposition**, but in general this is not possible or not unique. Actually whether there exists one algorithm to decompose them all remains to be a NP-hard problem ([[P vs NP]]).

```
src="https://i.upmath.me/svg/%0A%5Cbegin%7Btikzcd%7D%0AV%20%5Carrow%5Br%5D%20%26%20A%0A%5Cend%7Btikzcd%7D%0A" 

```
```
src="https://i.upmath.me/svg/%0A%5Cbegin%7Btikzcd%7D%0AV%20%5Carrow%5Br%2C%20dashed%5D%20%26%20A%0A%5Cend%7Btikzcd%7D%0A" 
```