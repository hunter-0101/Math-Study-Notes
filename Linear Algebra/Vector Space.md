Given [[Field]] $F$, an **$F$-vector space** is a triple $(V,+,\cdot)$ consisting of the set of **vectors** $V$, an addition operation $+:V\times V\to V$ and a scaler multiplication $\cdot:F\times V\to V$, satisfying: 
1. **Group structure**: $(V,+)$ is an abelian [[Group]].
2. **Distributivity**: $(a+b)v=av+bv,a(u+v)=au+av$.
3. **Compatibility**: $a(bv)=(ab)v$.
4. **Scaler multiplication identity**: $1v=v$.
In a purely algebraic manner, a vector space is a [[Module]] over a field. 
- **Direct sum decomposition**: we write:$$V=\bigoplus V_k$$if each $v\in V$ can be uniquely represented as $v=\sum v_k,v_k\in V_k$.
- **Hamel (Algebraic) basis**: a Hamel basis is a linearly independent set of [[Module]] generators. We sometimes use **Hamel-span** to emphasize that only finite combination of generators is allowed. A Hamel basis always exist for a vector space.
  **Proof**: denote $X$ the collection of linearly independent subsets of $V$. Obviously $X$ is not empty and is partially ordered ([[Order]]) by inclusion $\subset$. For any $Y\subset X$ s.t. $(Y,\subset)$ is totally ordered we pick $L_Y$ the union of all elements in $Y$, then $L_Y\in X$ is an upper bound for $Y$. Now by Zorn's lemma ([[Set]]) we can pick $L_\max$ a maximal element of $X$, which is a basis for $V$ by maximality.
	- **Discussion**: the fact that $v\in V$ cannot be expressed as a $K$-linear combination of $L_\max$ is equivalent to $v$ being linearly independent of $L_\max$ replies on division ring structure of $K$, since we're using the division operation that $$rv+\sum r_iv_i=0\quad\iff\quad v=-r^{-1}\sum r_iv_i$$This is actually a characterization of division ring, as discussed in [[Module]].
	- **Dimension**: given a basis $E=\set{e_i}$ of $V$ we define $\dim_F V=|E|$ if $|E|<\infty$, and say that $V$ is infinite dimensional if such finite basis does not exists. 
	  **Well-define-ness**: when two basis contains different number of elements then the larger one must be linearly dependent, via discussion on rank of [[Matrix]].
	- If $\mathbb K\subset\mathbb C$ is a field and $E$ is an infinite dimensional Banach space over $K$, then every Hamel basis for $E$ has at least cardinality $\mathfrak c=|\mathbb C|$.
	  **Proof**: denote the basis as $\set{v_j}_{j\in\mathbb N}$, by definition of Hamel basis we have $$E=\bigcup_{n\in\mathbb N}\operatorname{span}(v_j)_{j=1}^n$$This means $E$ is a countable union of proper subspaces of finite dimension, but every finite dimensional proper subspace of a normed space is nowhere dense, thus $E$ is a first category, contradicting the Baire category theorem.
- **Isomorphism**: an isomorphism $\phi$ between two vector spaces $V,W$ is a bijective linear transform, which is define below.
- **Dual system**: a dual system is a triple $(X,Y,b)$ consisting of vector spaces $X,Y$ and a non-degenerated [[Bilinear Form]] $$b:X\times Y\to F$$Sometimes we write $\braket{\cdot,\cdot}$ in place of $b$ when there's no risk of confusion. 
## Linear operator
For vector spaces $V, W$ over [[Field]] $F$, a **linear operator (transform)** is a map $T:V \to W$ that preserves addition and scalar multiplication. The collection of linear operators from $V$ to $W$ is denoted $\mathcal L(V,W)$, which is itself a vector space over $F$. Below we'll mostly assume that $$\dim V=n<\infty,\quad\dim W=m<\infty$$More general discussion can be found in [[Normed Vector Space]]. 
- **[[Matrix]] of linear operator**: given basis $\set{v_j}_{1\le j\le n},\set{w_i}_{1\le i\le m}$ for $V,W$ define the matrix of $T$ under the basis as the unique $A\in F^{m\times n}$ satisfying $$T(v_1,\cdots,v_n)=(T(v_1),\cdots T(v_n))=(w_1,\cdots,w_m)A_T$$Intuitively it's saying that $A_{ij}$ is the $w_i$ component in $T(v_j)$. The induced coordinate transform $A:F^n\to F^m$ is given by $x\mapsto y=Ax$ since we have that $$T\left(\sum_{j=1}^mx_jv_j\right)=\sum_{j=1}^nx_jT(v_j)=\sum_{j=1}^nx_j\sum_{i=1}^mA_{ij}w_i=\sum_{i=1}^mw_i\sum_{j=1}^nx_jA_{ij}=\sum_{i=1}^ny_iw_i\quad\Longrightarrow\quad y=Ax$$The usual formulas for $T\in\mathcal L(V)$ is just a special cases.
	- **Change of basis**: given $T\in\mathcal L(V,W)$ and two pair of basis $$(v_j')=(v_j)P,\quad (w_i')=(w_i)Q$$its matrix $A,B$ under old and new basis is associated, by coordinate formula, via $$T(v_j')=T((v_j)P)=T(v_j)P=(w_i)AP=(w_i')Q^{-1}AP\quad\Longrightarrow\quad B=Q^{-1}AP$$where the extraction of $P$ follows from linearity of $T$. 
	- **Non-natural identification**: as discussed in [[Matrix]], fixing a basis $\set{e_i}$ we have $$M_n(F)\cong\mathcal L(F^n),\quad A_T\leftrightarrow T$$However this identification is not natural, since it relies on the chosen basis, and change of basis would result in an extra [[Group Action]] by conjugation applied on the identification. 
- **Kernel & image**: we define $$\ker T=\set{v\in V:Tv=0},\quad\im T=\set{w\in W:Tv=w\text{ for some }v\in V}$$they're defined exactly similar to the level set and image of functions. 
	- Obviously $\ker T^k\subset\ker T^{k+1}$. More precisely we have $$\dim\left(\frac{\ker T^k}{\ker T^{k-1}}\right)\ge\dim\left(\frac{\ker T^{k+1}}{\ker T^k}\right),\quad\forall k\in\mathbb N$$since $T$ maps the right to the left in an injective fashion. As a corollary when it happens that $\ker T^m=\ker T^{m+1}$ then the kernel just stop expanding.
	- $T\in\mathcal L(V)$ is injective with $\im T$ closed iff it's bounded below, i.e., $\|Tx\|\ge c\|x\|,\forall x\in V$ for some $c>0$.
### Primary decomposition w.r.t a linear operator
Assuming $\dim V<\infty$ and take $T\in\mathcal L(V)$. By [[Polynomial Ring]] we know that the [[Characteristic Polynomial]]) of $T$ admit a irreducible factorization $$\chi_A(x)=\prod_ip_i^{d_i}\where(p_i,p_j)=1,\forall i\neq j$$The primary decomposition of $V$ induced by $T$ is the [[Invariant Subspace]] decomposition $$V=\bigoplus_{i}\ker p_i^{d_i}(A)$$**Proof**: by Bézout's identity ([[Ideal]]) there exists $h_i\in F[X]$ s.t. $$\sum_{i}h_iq_i=1\where q_i=\prod_{j\neq i}p_j^{d_j}$$Now we define the operator $$P_i=h_i(T)q_i(T)\imply\im P_i\subseteq\ker p_i^{d_i}(T)$$Hence any vector $v\in V$ can be written as $$v=\sum_{i=1}^nh_i(T)q_i(T)v\in\bigplus_i\im P_i\subseteq\bigplus\ker p_i^{d_i}(T)$$Meanwhile, by coprime-ness of $p_i$ we also deduce (still using Bézout's identity) that $$\ker p_i^{d_i}(T)\cap\ker p_j^{d_j}(T)=\varnothing,\quad\forall i\neq j$$which completes the direct sum decomposition part. Finally, we conclude by Interchangeability of $T$ and $p_i^{d_i}(T)$ that each $\ker p_i^{d_i}(T)$ is an invariant subspace of $T$. 
- **Primary decomposition induced by minimal polynomial**: the above argument also applies to the minimal polynomial $\mu_T$, and the induced primary decomposition is exactly the same. This is natural since $\chi_T,\mu_T$ shares the same irreducible factors, and they differ only in their multiplicities. Therefore the irreducible factors in $\mu_T$ are the highest power of each irreducible factors that actually "does work", and any higher power doesn't capture any more vectors. This can be explicitly seen by [[Jordan Normal Form]] (when it exists). 
- **Relation with primary decomposition theorem**: consider the action $$F[X]\act V:Xv\mapsto Tv$$which defines $V$ as an $F[T]$-[[Module]], while also establishes the isomorphism $$V\cong F[X]/\chi_T(X)$$Writing $\chi_T=\prod_i p_i^{d_i}$, then by the primary decomposition theorem ([[Ideal]]) we have $$(p)=\bigcap_i\paren{p_i^{d_i}}$$Which gives rise to the correspondence $$V_i\cong F[X]\left/p_i^{d_i}(X)\right.$$Therefore the primary decompose of vector space induced by a linear operator can be seen as a corollary of the general primary decomposition theorem. 
- **Minimal invariant subspace decomposition**: assuming that $F$ is algebraically closed, using results in [[Jordan Normal Form]] we can further refine the decomposition to $$V=\bigoplus_{i=1}^rV_i=\bigoplus_{i=1}^r\bigoplus_{j=1}^{g_i}V_i^j\where V_i=\ker(\lambda_iI-T)^{a_i},\quad\lambda_i\in\sigma(T)$$Here $V_i$ are **generalized eigenspaces** spanned by generalized eigenvectors, and $V_i^j$ are cyclic **minimal invariant subspaces** spanned by one single Jordan chain $$V_i^j=\span(v_{i,j}^k:1\le k\le m_{i,j})\where\begin{cases}(\lambda_iI-T)v_{i,j}^1=0\\(\lambda_iI-T)v_{i,j}^k=v_{i,j}^{k-1},&2\le k\le m_{i,j}\end{cases}$$Here $v_{i,j}^{m_{i,j}}$ is the generator of a Jordan chain. 
	- **Operator decomposition**: on top of the decomposition above, we can also decompose $T$ itself into operator components that act independently on them: $$T=\bigoplus_{i=1}^rT_i=\bigoplus_{i=1}^r\bigoplus_{j=1}^{g_i} T_i^j\where T_i^j=T|_{V_i^j},\quad T_i^j(V_i^j)\subset V_i^j$$The decomposition is also the most refined, although most of the time a decomposition into $T_i$ would suffices for the problem. 
	- **Nilpotent component**: by construction of the decomposition we have $$N_i^{a_i}=0\where N_i=\lambda_iI_i-T_i$$Sometimes writing $T_i=\lambda_iI_i-N_i$ could simplify the analysis. 
	- **Discussion**: this is the essential reason that invariant subspace decomposition is useful - it allows us to decompose the operator $T$ itself into smaller, simpler components to be handled independently on their own invariant subspace. 