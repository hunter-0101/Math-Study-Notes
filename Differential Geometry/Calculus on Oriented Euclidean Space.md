**Motivation**: the Euclidean space $\mathbb R^d$, as a space that we're mostly familiar with, serves as an intuitive prototype of general calculus on [[Smooth Manifold]]. This would serve as a preliminary for [[Differential Calculus on Smooth Manifold]] and [[Integral Calculus on Smooth Manifold]], covering things that will be invoked in the above two notes, and also providing motivations for definitions for concepts in them.
Note however this theory is built on Riemann calculus, and there is no [[Measure]] theory involved. For this direction, see geometric measure theory.

--- 
# Differential calculus
Below we're writing $M=\mathbb R^m$ for consistency in notation with [[Differential Calculus on Smooth Manifold]].
- **Tangent space**: given $v\in \mathbb R^d$ and $f:\mathbb R^d\to\mathbb R$ differentiable, by chain rule we have the directional derivative $D_v=\sum v_i\partial_i$. A **tangent vector** is defined to be the map $$v:C^1(\mathbb R^d)\to\mathbb R,\quad v(f(x))=D_v(f)(x)$$The space spanned by tangent vectors is the **tangent space** $T_pM$.
	- **Intuition**: instead of a "little arrow", tangent vectors in differential geometry describes how to measure the rate of change of a function. Precisely, a tangent vector, denoted $v$, is actually the partial differential given by $v$.
	- **Basis**: it's obvious that $T_p=\span(\partial_i)$.
	- **Germ**: for pair of a $C^\infty$ function $f$ and a neighborhood $U\subset M$ of $p$ define $$(f,U)\sim(g,V)\quad\iff\quad\exists W\subset U\cap V\text{ s.t. }f|_W=g|_W$$and call the equivalence class $(f,U)$ a germ of $f$ at $p$, denoted as $C^\infty_p(\mathbb R^d)$. It's obvious that $C_p^\infty$ forms an algebra under function addition and multiplication over $\mathbb R$.
	- **Derivation**: a derivation at $p$ is any $\mathbb R$-linear function $D:C_p^\infty\to\mathbb R$ satisfying **Leibniz rule** $$D(fg)=(Df)g+f(Dg)$$Set of derivations is denoted $\mathcal D_p(\mathbb R^d)$. We have the isomorphism $\phi:T_p\to\mathcal D_p$ given by $$\phi(v)=\sum v_i\partial_i|_p$$Injectivity is obvious, while surjectivity follows from Taylor's theorem ([[Differential Calculus on Euclidean Space]]) and Leibniz rule.
- **Vector field**: a vector field on open $U\subset M$ is a function $X:U\to T_pU$. We can write $$X_p=\sum a^i(p)\partial_i|_p,\quad\forall p\in U$$we say that $X\in C^\infty(U)$ if $a_i\in C^\infty,\forall i$.
## Differential form
The **cotangent space** $T_p^*M$ (i.e., dual space of $T_pM$) consists of covectors on tangent space, which is dual to the vector field defined above. A **covector field** on $U\subset M$ is a function $$\omega:U\to\bigcup_{p\in U}T_p^*U,\quad\omega(p)=\omega_p\in T_p^*$$which is referred to as a differential **$1$-form**. For $f\in C^\infty(U)$ consider the bilinear pairing $$T_pU\times C^\infty(U)\to\mathbb R,\quad(X_p,f)\mapsto\braket{X_p,f}=X_pf$$we define the **differential** $(df)_p=\braket{\cdot_p,f}$ as a function on the first argument of the pairing.
- **Basis**: $T_p^*=\span(dx^i)$ which is dual to $T_p=\span(\partial_i)$. Hence we can always write $$\omega_p=\sum a_i(p)(dx^i)_p$$In particular, for $f\in C^\infty$ we have the **coordinate expression of differential** $$df=\sum(\partial_if)dx^i$$where the coefficients are obtained by applying $\partial_i$ on both sides.
	- **$1$-form as a multi-linear function**: for $\omega$ and $X\in C^\infty(U)$ define $$\omega=\sum a_idx^i,X=\sum b^i\partial_i\quad \Longrightarrow\quad\omega(X)_p=\omega_p(X_p)=\sum a_ib^i$$Further we can show that $\omega$ is linear over the ring $C^\infty(U)$.
- **Exterior differentiable $k$-form**: by [[Exterior Algebra]] define $\omega\in A_k(T_pU)$ as $$\omega=\sum_{I=(i_1<\cdots<i_k)}a_I\bigwedge_{j=1}^kdx^{i_j}=\sum a_Idx^I$$This is analogous to the total derivative in [[Differential Calculus on Euclidean Space]].
	- **Wedge product between two forms**: it's natural by [[Exterior Algebra]] to define $$\omega\wedge\varphi=\sum_{I,J}a_Ib_J(dx^I\wedge dx^J)$$where $dx^I\wedge dx^J$ run through all possible combinations of basis terms of each form. Hence it's also anti-commutative and associative.
	- **Algebra of exterior differential form**: with wedge product as multiplication and degree of form as grading, the direct sum $$\Omega(U)=\bigoplus_{k=0}^\infty\Omega^k(U)$$forms a anti-commutative graded algebra over $\mathbb R$.
- **Exterior derivative**: in general for $\omega=\sum a_Idx_I\in\Omega^k(U)$ we define $d:\Omega^k\to\Omega^{k+1}$ by $$d\omega=\sum_Ida_I\wedge dx^I=\sum_I\left(\sum_j(\partial_j a_I)dx^j\right)\wedge dx^I\in\Omega^{k+1}(U)$$
	- **Anti-derivation of degree $1$**: we have that $$d(\omega\wedge\tau)=d\omega\wedge\tau+(-1)^{\deg\omega}\omega\wedge d\tau$$by the above coordinate expression.
	- **Closedness**: $d^2=0$, since in the resulting summation $dx^i\wedge dx^i=0$ while $dx^i\wedge dx^j$ has its alternating counterpart that cancels it out. 
	- $(df)(X)=Xf$ by definition.
	- **Characterization of exterior derivative**: if $D:\Omega^k\to\Omega^{k+1}$ is anti-derivation of degree $1$, is closed, and $(Df)(X)=Xf$, then $D=d$.
	  **Proof**: it suffices to show that $D(fdx^I)=d(fdx^I)$ for all $I=(i_1<\cdots<i_k)$. By $$(Df)(X)=Xf=df(X),\quad\forall F\in C^\infty$$we have $Df=df$, while a simple induction with anti-derivation property shows that $D(dx^I)=0$, hence $$D(fdx^I)=Df\wedge dx^I+fD(dx^I)=df\wedge dx^I=d(fdx^I)$$which complete the proof.
- **Closed/exact form**: $\omega\in\Omega^k$ is closed if $\omega\in\ker d$, and is exact if there exists $\omega\in\im d$. By $d^2=0$ we know that $\im d\subset\ker d$, i.e., all exact forms are closed.
---
# Integral calculus
We say that $A\subset\mathbb R^m$ is a **domain of integration** if it's bounded with topological boundary being a null set ([[Lebesgue Measure]]). Integration of top forms on $\mathbb R^m$ is basically the same as [[Integral Calculus on Euclidean Space]]: for $\omega=f(x)dx^1\wedge\cdots\wedge dx^m$ define $$\int_A\omega=\int_Af(x)dx^1\wedge\cdots\wedge dx^m=\int_Af(x)dx^1\cdots dx^m$$Note that the order must be $I=(1,\cdots,m)$ to transform integration of m-form into an ordinary Riemann integral.
- **Discussion**: the concept of differential form essentially provides a algebraically rigorous framework for the notation of differentiation and orientation
- **Change of variable**: given $(U,x^i),(V,y^i)$ take a diffeomorphism $T:V\to U$ with $i$-th component $T^i=x^i\circ T=T^*(x^i)$, denote $J_T$ the Jacobian $[\partial T^i/\partial y^j]$, then $$dT^1\wedge\cdots\wedge dT^m=(\det J_T )dy^1\wedge\cdots\wedge dy^m$$hence assuming $U,V$ are connected, we have $$\begin{align}\int_VT^*\omega&=\int_V(T^*f)T^*dx^1\wedge\cdots\wedge T^*dx^m\\&=\int_V(f\circ T)dT^1\wedge\cdots\wedge dT^m\\&=\int_V(f\circ T)(\det J_T)dy^1\wedge\cdots\wedge dy^m\\&=\int_V(f\circ T)(\det J_T)dy^1\cdots dy^m \end{align}$$where the first two equality follows from commutation of pushforward ([[Differential Calculus on Smooth Manifold]]). Meanwhile, by [[Integral Calculus on Euclidean Space]] we have $$\int_U\omega=\int_Ufdx^1\cdots dx^m=\int_U(f\circ T)\left|\det J_T\right|dy^1\cdots dy^m$$The above two equalities yield $$\int_VT^*\omega=\sgn(\det J_T)\int_U\omega$$Intuitively there is only an extra sign term without scaling value because the latter is already encapsulated within the expression $T^*\omega$.
## Stokes' theorem
**Theorem**: given $M=\mathbb R^m$ or $M=\mathcal H^m=\set{x\in\mathbb R^m:x^m\ge0}$, for $\omega\in\Omega_c^{m-1}(M)$ we have $$\int_Md\omega=\int_{\partial M}\omega$$**Proof**: for $M=\mathbb R^m$ we have $\partial M=\varnothing$, hence RHS equals $0$, while write $$\omega=\sum_{i=1}^k(-1)^{i-1}f_idx^1\wedge\cdots\wedge \widehat{dx^i}\wedge\cdots dx^k\quad\Longrightarrow\quad d\omega=\left(\sum_{i=1}^k\partial_if_i\right)dx^1\wedge\cdots\wedge dx^k$$Hence we can apply Fubini's theorem ([[Riemann Integral]]) and use compactness assumption to conclude, via the fundamental theorem of calculus, that $$\int_{\mathbb R^m}d\omega=\sum_i\int_{\mathbb R^m}\partial_if_idx^1\cdots dx^m=0=\int_{\partial \mathbb R^m}\omega$$For $M=\mathcal H^m$, the above process carries over except $\partial_mf_mdx^1\cdots dx^m$. Again by FTC we get $$\int_{\mathcal H^m}d\omega=\int_{\mathbb R^{m-1}}-f_k(x_1,\cdots,x_{k-1},0)dx^1\cdots dx^{k-1}$$Meanwhile, since $\partial\mathcal H^m\cong\mathbb R^{m-1}$ and $dx^m=0$ on this boundary, the only term that does not vanish on the boundary is the one without $dx^m$, which is $$\omega=(-1)^{m-1}f(x_1,\cdots,x_{m-1},0)dx^1\wedge\cdots\wedge dx^{m-1}\quad\Longrightarrow\quad\int_{\partial\mathcal H^k}\omega=(-1)^k\int_{\mathbb R^{m-1}}\omega=\int_{\mathcal H^m}d\omega$$This completes the second case, as well as the proof of the theorem.
- **Intuition**: the above proof illustrates the intuition for generalized Stokes' theorem quite well - it's essentially using Fubini's theorem ([[Lebesgue Integral]]) to break an multi-integral into repeated integral, and then use FTC ([[Differential Calculus on Euclidean Space]]) to bridge between differential forms and boundary operators. Note however that what we state above is just **one proof strategy**, not the **fundamental mechanism**. Further insights is discussed below.
### Interpretation under homological algebra
Consider the singular chains $C_*(M)$ with boundary $\partial$ ([[Homology]]) $$\cdots\to C_{n+1}(M)\xto{\partial}C_n(M)\xto{\partial} C_{n-1}(M)\to\cdots$$and differential forms $\Omega^*(M)$ with exterior derivative $d$ ([[Exterior Algebra]]) $$\cdots\to\Omega^{n-1}(M)\xto{d}\Omega^n(M)\xto{d}\Omega^{n+1}(M)\to\cdots$$If we define the natural paring by $$\braket{\cdot,\cdot}:C_k(M)\times \Omega^k(M)\to\mathbb R,\quad\braket{c,\omega}\mapsto\int_c\omega$$then the generalized Stokes' theorem essentially says that $$\braket{\partial c,\omega}=\braket{c,d\omega}$$so integration defines a chain map (morphism of complexes), inducing a pairing on homology and cohomology. Further notice that:
1. If $c$ is boundary with $c=\partial b$, then for any $d\omega=0$ we have $$\int_c\omega=\int_{\partial b}\omega=\int_bd\omega=\int_b0=0$$so the integral vanishes on boundaries when the form is closed. 
2. If $\omega$ is exact with $\omega=d\mu$, then for any $\partial c=0$ we have $$\int_c\omega=\int_cd\mu=\int_{\partial c}\mu=\int_0\mu=0$$so a closed chain integrates to zero against every exact form.
So we obtain a bilinear paring on homology and de Rham cohomology [[De Rham Theory]]: $$H_k(M,\mathbb R)\times H_\text{dR}^k(M)\to\mathbb R,\quad([c],[\omega])\mapsto\int_c\omega$$That is the explicit passage: Stokes is the technical identity that makes the quotienting (mod boundaries / mod exact forms) legitimate.
- **General definition**: integral is natural transformation ([[Category]]) of a functor sub-manifolds, to de Rham functor of currents. With contravariant dual functor an integral equivalently can be seen as natural transformation of de Rham functor of differential forms to a functor of measures. (ref: *Stokes law is a chain morphism. Integral is a natural transformation of functors* by Zbigniew Oziewicz)
- **Geometric measure theory**: Stokes holds for very rough domains (Lipschitz manifolds, normal currents), far beyond classical Fubini settings. The theorem is built into the axioms of integration on currents.