**Motivation**: for [[Solving Linear System]] a one generally applicable idea is to first find $$Ax_i=e_i,1\le n\le n\quad\text{where}\quad V=\span(e_i:1\le i\le n)$$then the solution to $Ax=b$ can be constructed via $x=\sum_{i=1}^nb_ix_i$. Green's function generalizes this idea to functions as a continuous version.

---
A **Green's function** is some $G_s=G(t,s)$ s.t. $LG_s=\delta_s$ the Dirac Delta function ([[Special Function Gallery]]). Observe that by setting $$\phi_p(t)=\int_\mathbb R f(s)G(t,s)ds\quad\Longrightarrow\quad L\phi_p(t)=\int_\mathbb Rf(s)LG(t,s)ds=\int_\mathbb Rf(s)\delta(t-s)ds=f(t)$$here interchangeability of $L$ and $\int$ is validated by [[Differentiation Under the Integral Sign]], hence solving $Lx=f(t)$ reduces to finding its Green's function, which is also called the **fundamental solution** of the operator $L$. Now since $\delta(t-s)=0,\forall t\neq s$ by [[Linear ODE]] we may assume $$G_s(t)=\begin{cases}0,&t<s\\\sum_{i=1}^nc_i\phi_i(t),&t>s\end{cases}\quad\text{where}\quad c_i\in\mathbb R$$while at $t=s$ we expand $L$ into each differential terms: $$LG_s=\delta_s\quad\iff\quad\sum_{i=0}^na_i(t)\frac{d^i}{dt^i}G_s(t)=\delta_s(t)$$Hence to ensure match of function behavior we require $$\left.\frac{d^n}{dt^n}G_s(t)\right|_{t=s}=\frac{\delta(0)}{a_n(s)}\quad\Longrightarrow\quad\left.\frac{d^{n-1}}{dt^{n-1}}G_s(t)\right|_{t=s}=\frac{H(0)}{a_{n-1}(s)}\quad\Longrightarrow\quad\cdots$$Going forward would yields $|x|\chi_{[0,\infty)},x^2\chi_{[0,\infty)}$, etc.. Now for $n\ge2$ the above conditions imply $$\begin{cases}\sum_{i=1}^nc_iy_i^{(j)}(s)=0,&0\le j\le n-2\\ a_n(s)\sum_{i=1}^nc_iy^{(n-1)}(s)=1\end{cases}$$Finally treating $c_i$ as functions of $s$ and putting everything back into $\phi_p$ we get $$\phi_p(t)=\int_\mathbb Rf(s)G(t,s)ds=\int_{-\infty}^t f(s)\sum_{i=1}^nc_i(s)\phi_i(t)ds=\sum_{i=1}^n\phi_i(t)\int_{-\infty}^tf(s)c_i(s)ds$$Here the integral terms are exactly the variation of parameters satisfying the assumptions given above. There are two important steps discussed below:
1. **Reconstruction of a solution via integral**: we can interpret $G_s$ as an [[Integral Operator]] that serves as the inverse of $L$. This is valid in the [[Distribution]] sense. Moreover, this can be interpreted under the [[Spectrum]] framework, where we're trying to find the spectral decomposition of $L^{-1}$.
2. **Comparison of coefficients via function behavior**: this makes sense under the perspective of [[FT on L2]]: differentiation is turned into multiplication with $\xi$, hence coefficients can be compared just as we've done in [[Polynomial]].
## Worked example
In general the steps of finding the Green's function for a linear differential operator with a set of boundary conditions proceeds as:
1. **Solve the homogeneous equation**: by solving $Ly=0$, we obtain its fundamental set of solutions $\phi_i$. Then we can write $$G(x,y)=\begin{cases}\displaystyle\sum_{i=1}^n c_i^1\phi_i(x),&x<y\\\displaystyle\sum_{i=1}^nc_i^2\phi_i(x),&x>y\end{cases}$$here $c_i^j$ are coefficients to be determined.
2. **Impose the constraints of BV**: by imposing BV on $G(x,y)$ defined above we can usual derive some constraints on these coefficients. After this step there will be only $n$ degree of freedom left for $c_i^j$,
3. **Impose the constraint of delta function**: we adjust the remaining $n$ degree of freedom to ensure that $G(x,y)$ behaves exactly the same as $\delta_y$ by the expressions listed above.
In general, step 2, 3 use $n$ degrees of freedom respectively, and in this way we determines the specific Green's function for a given BVP.
### Fundamental solution of $y''=f$
Below we deduce the Green's function for $\frac{d^2}{dx^2}$ on $[0,1]$. We wanna seek some $G(x,s)$ defined on $[0,1]\times[0,1]$ s.t. $$\frac{d^2}{dx^2}G(x,s)=\delta(x-s)$$then the solution to $y''=f$ will be given by $$y(x)=\int_0^1 G(x,s)f(s)ds$$**Solution**: since away from the diagonal $x=s$ we have $G''(x,s)=0$, hence fixing $s$ we have $G(\cdot,s)$ piecewise linear. This means we can assume $$G(x,s)=\begin{cases}A_1(s)x+B_1(s),&0\le x<s\\ A_2(s)x+B_2(s),&s<x\le1\end{cases}$$We impose several conditions based on the assumptions:
1. **Dirichlet BC**: $G(0,s)=G(1,s)=0$. This is valid since a extra linear term vanishes under second order derivative.
2. **Continuity at $x=s$**: $G(s^-,s)=G(s^+,s)$.
3. **Jump condition from integrating $G''=\delta$ across $s$**: $G'(s^+,s)-G'(s^-,s)=1$.
Using these conditions we can solve $G(x,s)$ to be $$G(x,s)=\begin{cases}(s-1)x,&0\le x\le s\\ s(x-1),&s\le x\le1\end{cases}$$Now this can be used to express the solution to $y''=f$ using an integral form.
- **Discussion about non-uniqueness**: if the homogeneous equation $y''=0$ has non-trivial solutions that satisfy given BC then the inverse is not unique, the Green’s function above implicitly encodes choosing the particular inverse that enforces the boundary conditions. For other BC the jump condition changes or the homogeneous part must be added.
### Poisson problem in a ball
Consider the Dirichlet Poisson problem $$\begin{cases}\Delta_xu(x)=f(x),&x\in B_R\\u(x)=0,&x\in\partial B_R\end{cases}$$As discussed in [[Laplace's Equation]], we can obtain the fundamental solution for $\Delta_x$ as $$\Phi(x)=\begin{cases}-\dfrac{1}{2\pi}\ln|x|,& n=2\\ \dfrac{1}{n(n-2)\alpha(n)}\dfrac{1}{|x|^{n-2}},& n\ge3\end{cases}$$and a solution is expected to be of the form $u=\Phi*f$. However the fundamental solution does not verify the BC, hence we seek instead the Green's function of the form $$G(x,y)=\Phi(x-y)-h(x,y)\quad\text{where}\quad \Delta_xh(\cdot,y)=0,\forall y$$One possible method is to utilize the Poisson kernel. Define $$h(x,y)=\int_{\partial B_R}P_R(x,\xi)\Phi(\xi-y)dS(\xi)$$then by Poisson's equation the boundary value can be canceled out.
- **Discussion on domain**: the geometry (ball) is what allows an explicit elementary correction (via inversion). On a general domain we still do the “fundamental solution plus harmonic correction,” but computing the harmonic correction requires solving a boundary integral equation - that is precisely the origin of **boundary integral methods** and **Fredholm theory**.

---
## Integral kernel perspective
The essential pattern stays the same when we march from ODE to PDE - given $L_x$ in several variables we find $G(x,y)$ with $$L_xG(x,y)=\delta(x-y)$$given some BC, and write the solution to $L_xu=f$ as $$u(x)=\int_\Omega G(x,y)f(y)dy\quad\text{(with some potential boundary terms)}$$This is when the **Schwartz kernel theorem** ([[Distribution]]) comes into the picture: if we write $$L\phi=f\quad\iff\quad\phi=L^{-1}f$$then the Green's function $G(x,y)$ is exactly the kernel corresponding to $L^{-1}$.
## Operator perspective 
Take $L$ a linear differential operator, then by the discussion above we have $$LT_G=I\quad\text{where}\quad T_Gf=\int G(x,y)f(y)dy$$that is, Green's function is the kernel of the integral operator that serves as the **right inverse** to $L$. Whether it's a left inverse depends on the operator itself and BV imposed by the DE. In general the best we can get is that $T_GL=P$ a projection that annihilates $\ker L$. using operator theory language, for $\lambda\in\mathbb C$ the resolvent ([[Spectrum]]) is $$R_L(\lambda)=(\lambda I-L)^{-1}$$When the resolvent exists and is a continuous linear operator between test/distribution or Sobolev spaces, then by Schwartz kernel theorem it has a kernel $$G_\lambda(x,y)\in\mathcal D'(\Omega\times\Omega)\quad\text{s.t.}\quad\left((\lambda-L)^{-1}f\right)(x)=\int_\Omega G_\lambda(x,y)f(y)dy$$and, in distributional language, in $x$ we have $$(\lambda-L_x)G_\lambda(x,y)=\delta(x-y)$$Hence the Green's function is nothing but the resolvent kernel at the spectral parameter $\lambda$. The classical Green's function for $L$ is the resolvent at $\lambda=0$, provided $0$ lies in the resolvent set. When $\lambda$ sits in the spectrum the resolvent does not exist as a bounded operator, and one must speak about generalized inverses, parametrices, or distributional inverses.

---
## Application in integral inequality
We use the problem discussed in [[Frequency Splitting]] to illustrate how Green's function can be used to establish integral inequality. Below we show that result that $$\|f'\|_1\le r\|f\|_1\|f''\|_1,\quad r\in\mathbb R$$**Proof**: consider the operator $$L_\alpha=\alpha I-\frac{d^2}{dx^2}$$its Green's function on $\mathbb R$ is given by $$K_\alpha(x)=\frac{1}{2\sqrt\alpha}e^{-\sqrt\alpha|x|},\quad L_\alpha K_\alpha=\delta$$and by differentiation we have $$K_\alpha'(x)=-\frac{1}{2}\sgn(x)e^{-\sqrt\alpha|x|}\quad\Longrightarrow\quad\|K_\alpha'\|_1=\frac{1}{\sqrt\alpha}$$Now convolve $L_\alpha$ with $f$, then we have $$L_\alpha f=\alpha f-f''\quad\Longrightarrow\quad f=K_\alpha*(\alpha f-f'')\quad\Longrightarrow\quad f'=K_\alpha'*(\alpha f-f'')$$Take $L^1$ norm and apply Young's [[Convolution]] inequality we get $$\|f'\|_1\le\alpha\|K_\alpha'\|_1\|f\|_1+\|K_\alpha'\|_1\|f\|_1=\sqrt\alpha\|f\|_1+\frac{1}{\sqrt\alpha}\|f''\|_1$$now it suffices to use AM-GM inequality to derive the optimal coefficient.
- **Interpretation under [[Frequency Splitting]]**: notice that $$\mathcal FK_\alpha(\xi)=\frac{1}{\alpha+\xi^2}\quad\Longrightarrow\quad\mathcal FK_\alpha'(\xi)=\frac{2\pi i\xi}{\alpha+\xi^2}$$so convolving with $K_\alpha$ is exactly applying a smooth frequency multiplier that simultaneously picks up the low-frequency piece and the high-frequency piece.
 

--- 
## Historical timeline
Below we list the timeline of development of all topics related to the idea, concept, theory, and application of Green's function.
- **1828 - George Green.** Green’s short essay (1828) introduced what we now call Green’s functions for potential problems. (Early origin of the name and method.)
- **mid-1800s - Sturm–Liouville and eigenfunction expansions.** Sturm and Liouville studied second-order problems whose eigenfunctions give orthogonal expansions (mid–19th c.). This seeds the “infinite matrix / spectral expansion” viewpoint.
- **late 1800s to early 1900s - potential theory & integral equations.** The study of potential theory and boundary integral methods grew; Fredholm’s fundamental paper on integral equations appears ~**1903** (Fredholm kernels and determinants). Hilbert and Schmidt develop kernel theory; Hilbert’s work on integral equations links to spectral theory.
- **early 1900s - Hilbert and spectral theory.** Hilbert (and later Riesz) develop operator and spectral ideas for integral operators; eigenfunction expansions become central tools.
- **1920s–1930s - Sobolev & weak derivatives; Dirac.** Sobolev introduces spaces now bearing his name (1930s) giving weak-derivative viewpoint; Dirac (1927 onward) uses the delta “function” in quantum theory as a convenient but informal object.
- **1930s–1950s - functional analysis crystallizes.** Banach spaces, bounded operators, and early operator theory: Riesz, von Neumann, and others push the abstract operator viewpoint and spectral theorem for self-adjoint operators (late 1920s–1930s). 
- **1940s–1950s - Laurent Schwartz and distributions.** Schwartz develops the theory of distributions (late 1940s, published ~1950–1951), giving a rigorous home for Dirac’s delta and for fundamental solutions / Green’s functions that are singular.
- **1950s - Schwartz kernel theorem.** The kernel theorem (Schwartz) identifies continuous linear maps between suitable test-function spaces with distributions on product space — the rigorous statement of “operator ↔ kernel.” (Early 1950s.)
- **1950s–1960s - semigroup theory, resolvents, Dunford functional calculus.** The resolvent formalism and functional calculus (Dunford, later operational calculus) are developed and used to study evolution equations; Hille–Yosida theorem and Stone’s theorem connect generators and semigroups.
- **1950s–1970s - PDE theory and Sobolev spaces expand.** Elliptic regularity, existence/uniqueness in Sobolev spaces, and distributional fundamental solutions become standard (Agmon, Douglis, Nirenberg, others).
- **1960s onward - pseudodifferential operators & microlocal analysis.** Kohn–Nirenberg, Hörmander, and others develop pseudodifferential operator calculus and microlocal tools (1960s onward) - these extend the “Green/resolvent” viewpoint to analyze singularities and parametrices.
- **1960s–1970s - index theory & global analysis.** Atiyah–Singer index theorem (1963–1968) shows deep relations between elliptic operators, their parametrices (generalized inverses), and topology.
- **Late 20th c.–present - operator algebras, numerical boundary integral methods, modern spectral theory.** The resolvent/kernel picture enters C*-algebras, scattering theory, numerical methods (boundary element methods), and refined PDE theory.