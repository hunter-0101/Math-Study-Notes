In this note we start with differential calculus for functions $f:\mathbb R\to\mathbb R$, and then generalize it to the higher-dimensional case. 
- **Algebraic point of view**: in algebra (in particular, fields like [[Smooth Manifold]]) the derivative is generalized to the concept of "derivation", which is defined in a purely algebraic manner. This is different from definitions below, and illustrates the difference in essential idea of analysis and algebra.

---
Define the four **Dini numbers** of [[Function on Euclidean Space]] $f:I\to\mathbb R,I\subset \mathbb R$ as $$\begin{align}&D^+(F)(x)=\limsup_{h\searrow0}\Delta_h(F)(x)&D_+(F)(x)=\liminf_{h\searrow0}\Delta_h(F)(x)\\&D^-(F)(x)=\limsup_{h\nearrow0}\Delta_h(F)(x)&D_-(F)(x)=\liminf_{h\nearrow0}\Delta_h(F)(x)\end{align}$$obviously $D_+\le D^+,D_-\le D^-$ by definition ([[Series]]). When $D^+=D^-=D_+=D_-$ the following limit exists, which we'll call the **derivative** of $f$ at $x$: $$\frac{df}{dx}=f'(x)=\lim_{h\to0}\Delta_hf=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$The space of functions that are **continuously differentiable** over $I$ is denoted $C^1(I)$. We can further iteratively define $C^k(I),k\in\mathbb N$. 
- **Discontinuity of derivative**: given $f$ differentiable on $[a,b]$ by Darboux's theorem $f'$ cannot have jump discontinuity, and by definition and mean value theorem $f'$ cannot have removable discontinuity. However other kind of discontinuities are allowed, for instance, consider $$f(x) = \begin{cases} x^2\sin(\frac{1}{x}), \quad &x \neq 0 \\ 0, \quad &x=0\end{cases}$$then this function has an oscillating discontinuity of $f'$ at $0$. Actually we can construct a function whose derivative is discontinuous on a dense subset of positive [[Lebesgue Measure]]. 
- **Arithmetic property**
	- **Linearity**: by linearity of limit ([[Series]]) we have $$\frac{d}{dx}\sum_{i=1}^nf_i=\sum_{i=1}^n\frac{df_i}{dx},\quad\forall f_i\in C^1,1\le i\le n$$Therefore $C^k(I)$ is a [[Vector Space]].
	- **Derivative of product & quotient**: by properties of limit ([[Series]]) we can show that $$\frac{d(fg)}{dx}=\frac{df}{dx}g+f\frac{dg}{dx}\quad\Longrightarrow\quad\frac{d}{dx}\prod_{i=1}^nf_i=\sum_{i=1}^n\frac{df_i}{dx}\prod_{j\neq i}f_j$$and similarly, we can also show that $$\frac{d}{dx}\frac{f}{g}=\frac{f'g-g'f}{g^2}$$they'll be called the **product** & **quotient rule of differentiation**. 
	- **Chain rule**: by properties of limit ([[Series]]) given $f,g\in C^1$ we have $$\frac{d}{dx}(f\circ g)=f'(g)\cdot g'$$here we're assuming that $f$ is differentiable on the image of $g$.
- **Little $d$ operator**: for convenience we also define $$df=f'dx\quad\iff\quad f(x+\Delta x)-f(x)=f'(x)\Delta x+o(|\Delta x|)$$and some calculations involving differentials can be simplified via this notation. However we should always keep in mind that this is **not of first principle** - the operator $\frac{d}{dx}$ is a whole, and it makes no (rigorous) sense to manipulate the "numerator" and "denominator". The common utilities of $d$ are essentially based on [[Taylor's Theorem]] and related theory.
	- **Discussion on notation**: we would encounter the notation $d,\partial$ a lot in the theory of differential manifold, but that's not differential - that's derivation defined via [[Exterior Algebra]]. Only by defining in an algebraic way can we write $d$ individually and say that it's indeed a "differential".
## Basic theorems
- **Extreme value theorem**: continuous $f$ on a compact domain $K$ attains a maximum and minimum, each at least once. 
  **Proof**: $f$ is bounded on $K$ by considering its oscillation ([[Function on Euclidean Space]]), hence by the least upper bound property ([[Order]]) there is a maximum $M$ of $f$ within the domain. Take $x_n\in K$ with $f(x_n)\to M$, then by boundedness we have $x=\lim x_n\in K$. Similarly we can prove the minimum case.
- **Darboux's theorem**: if $f\in C([a,b])$ is differentiable, then $f'$ has intermediate value property.
  **Proof**: WLOG pick $f'(a)>y>f'(b)$, then by extreme value theorem $\phi(y)=f(y)-yt$ reaches its maximum at some point on $[a,b]$. By assumption the extremum cannot be reached at $t=a,b$, hence there exists $t_0\in(a,b)$ s.t. $f(t_0)$ is a maximum, and by Fermat's theorem we have $\phi'(t_0)=0$, i.e., $f'(t_0)=y$.
- **Rolle's theorem**: given $f\in C^1([a,b])$ with $f(a)=f(b)$ there exists $\xi\in[a,b]$ s.t. $f'(\xi)=0$.
  **Proof**: by extreme value theorem $f$ attains both its maximum and minimum on $[a,b]$. If both are at the end points then $f\equiv C$, otherwise the derivative at the other extremum must be $0$.
	- **Corollary**: replace $f$ by $f-g$ we know that if $f(a)=g(a),f(b)=g(b)$ there exists $\xi\in[a,b]$ s.t. $f'(\xi)=g'(\xi)$. Further we know that if $f,g\in C^{(n+1)}$ with $n+1$ common zeros there exists $\xi$ lying between the zeros s.t. $f^{(n+1)}(\xi)=g^{(n+1)}(\xi)$.
- **Mean value theorem**: given $f\in C^1([a,b])$ there exists $\xi\in[a,b]$ s.t. $$\frac{f(b)-f(a)}{b-a}=f'(\xi)$$the proof is straightforward by Rolle's theorem applied to $h(x)=f(x)-x$.
	- **Cauchy's mean value theorem**: given $f,g\in C^1([a,b])$ there exists $\xi\in[a,b]$ s.t. $$\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(\xi)}{g'(\xi)}$$We only need to apply Rolle's theorem to $h(x)=(g(b)-g(a))f(x)-(f(b)-f(a))g(x)$ and rearrange the terms to get the result. Intuitively, consider the curve $\gamma$ defined by $\gamma(t)=(f(t),g(t)),t\in[a,b]$, then the theorem is saying that there exists $P\in\gamma$ s.t. the tangent at $P$ is parallel to $\gamma(a)\to\gamma(b)$.
	- **L'HÃ´pital's rule**: if $f,g\in C^1$ with $f(a)=g(a)=0$, then by mean value theorem $$\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{\frac{f(x)-f(a)}{x-a}}{\frac{g(x)-g(a)}{x-a}}=\lim_{x\to a}\frac{f'(x)}{g'(x)}$$the equality follows from mean value theorem and property of limit.
	- **Limitation**: the exact value of $\xi$ is not known, hence leaving an irreparable flaw. A simple example illustrating this is that $$\frac{e^b-e^a}{b-a}\ge e^{\frac{a+b}{2}},\quad\forall a,b\in\mathbb R$$which can actually be proved via Jensen's formula. [[Lp Space]]
- **Fundamental theorem of calculus (derivative)**: given $F:[a,b]\to\mathbb R$ differentiable and $F'$ integrable on $[a,b]$, we have $$\int_a^bF'(x)dx=F(b)-F(a)$$**Proof**: given any partition $x_i$ of $[a,b]$, by mean value theorem there exists $\xi_i\in[x_i,x_{i+1}]$ s.t. $$F(x_{i+1})-F(x_i)=F'(\xi_i)\Delta x_i,\quad\Delta x_i=x_{i+1}-x_i$$by summing over $i$ we get $$F(b)-F(a)=\sum_i(F(x_{i+1})-F(x_i))=\sum_iF'(\xi_i)\Delta x_i$$Now let $\|\Delta x_i\|_\infty\to0$, then the above is exactly the definition of [[Riemann Integral]]. Note that this also referred to as the Newton-Leibniz formula.
	- **Discussion**: integrability of $F'$ is necessary, since as discussed in the last section, the derivative could have positive measure discontinuity, hence not integrable, making the above expression meaningless.
- **General Leibniz rule**: it's easy to verify from basic arithmetic properties that $$(fg)^{(n)}=\sum_{k=0}^n\binom{n}{k}f^{(n-k)}g^{(k)}$$for $f,g$ that makes the above differentials well-defined.
---
# Several variable: $f\in\mathbb R^n\to\mathbb R$
For convenience we use the following **multi-index notation**: $$x^\alpha=\prod_{i=1}^nx_i^{\alpha_i},\quad\binom{\alpha}{\beta}=\prod_{i=1}^n\binom{\alpha_i}{\beta_i},\quad |\alpha|=\sum_{i=1}^n\alpha_i,\quad\alpha!=\prod_{i=1}^n\alpha_i!$$where $\alpha=(\alpha_i)$ and similarly for $\beta$.
If in some neighborhood of $x_0$ within $\mathbb R_i$ the function $f$ can be approximated linearly, define $$\frac{\partial f}{\partial x_i}(x_0)=\lim_{\Delta x_i\to0}\frac{f(x_0+\Delta x_i)-f(x_0)}{\Delta x_i}\quad\iff\quad f(x_0+\Delta x_i)=f(x_0)+\frac{\partial f}{\partial x_i}(x_0)\Delta x_i+o(\Delta x_i)$$Here $o(\Delta x)$ can be interpreted as either $(o(\Delta x_1),\cdots,o(\Delta x_n))$ or $o(|\Delta x|)$.
- **Higher order partial derivative**: denote $$\frac{\partial^2 f}{\partial y\partial x}=\frac{\partial}{\partial y}\cdot\frac{\partial f}{\partial x}$$and $x,y$ are exchangeable if the corresponding differentiation is continuous.
	- **Schwarz's theorem**: for a function $f:\Omega\to R$ defined on a set $\Omega\subset\mathbb R^n$, if $p\in\mathbb R^n$ is a point such that some neighborhood of $p$ is contained in $\Omega$, and $f$ has continuous second partial derivatives on that neighborhood, then for all $i,j\in\{1,2,\cdots,n\}$, we have $$\frac{\partial^2}{\partial x_i\partial x_j}f(p)=\frac{\partial^2}{\partial x_j\partial x_i}f(p)$$**Proof**: the key idea is to use mean value theorem (ensured by continuity) to express $$w(x,y)=f(x+h,y+k)-f(x+h,y)-f(x,y+h)+f(x,y)$$in two symmetric orders, and again use continuity to get $$\frac{\partial^2}{\partial x\partial y}f(x,y) =\frac{\partial^2}{\partial y\partial x}f(x, y)$$Note that this is a sufficient condition, and can actually be weakened to continuity hold by only one of them.
- **Space of continuously differentiable functions**: with the multi-index notation $$\partial^\alpha=\frac{\partial^{|\alpha|}}{\partial x_1^{\alpha_1}\cdots\partial x_d^{\alpha_d}}$$using definition of $C(\Omega)$ ([[Function on Euclidean Space]]) we define $$C^m(\Omega)=\set{f\in C(\Omega):\partial^\alpha f\in C(\Omega),\forall|\alpha|\le m}$$and similarly for $\overline\Omega$, with the canonical norm $$\|f\|_{C^m(\overline\Omega)}=\max_{|\alpha|\le m}\|\partial^\alpha f\|_{C(\overline\Omega)}$$The space of **infinitely differentiable functions** is defined as $$C^\infty(\Omega)=\bigcap_{m=0}^\infty C^m(\Omega)$$with $C^\infty(\overline\Omega)$ defined similarly.
	- **[[Banach Space]] structure**: $C^m(\overline\Omega)$ is Banach under any of the two equivalent norms: $$\|f\|_{C^m(\overline\Omega)}=\max_{|\alpha|\le m}\|\partial^\alpha f\|_{C(\overline\Omega)}\quad\text{or}\quad\|f\|_{C^m(\overline\Omega)}=\sum_{|\alpha|\le m}\|\partial^\alpha f\|_{C(\overline\Omega)}$$where $\|\cdot\|_{C(\overline\Omega)}=\|\cdot\|_\infty$ is the canonical norm on $C(\overline\Omega)$ ([[Function on Euclidean Space]]).
	  **Proof**: both expressions are obviously norms, being the maximum/summation of supremum norms ([[Vector Space]]). For any one of them notice that $$f_n\xto{C^m(\overline\Omega)}f\quad\Longrightarrow\quad \partial^\alpha f_n\xto{C(\overline\Omega)}f_\alpha,\quad\forall|\alpha|\le m$$By [[Function on Euclidean Space]] this ensures $f\in C^m(\overline\Omega)$. For equivalence, notice that $$\max_{|\alpha|\le m}\|\partial^\alpha f\|_{C(\overline\Omega)}\le\sum_{|\alpha|\le m}\|\partial^\alpha f\|_{C(\overline\omega)}\le\binom{m+d}{d}\max_{|\alpha|\le m}\|\partial^\alpha f\|_{C(\overline\Omega)},\quad\forall f\in C^m(\overline\Omega)$$by positive definiteness of norm ([[Vector Space]]). 
- **Extremum**: if $a\in E\subset\mathbb R^n$ is an extremum, then $$\frac{\partial f}{\partial x_i}=0,\quad\forall1\le i\le n$$This is obvious from the definition of partial derivative.
	- **Hessian**: for $f\in C^2$ its Hessian is given by $H_f=\begin{bmatrix}\frac{\partial^2 f}{\partial x_i\partial x_i}\end{bmatrix}_{n\times n}$. We have that $a$ is a maximum/minimum of $f$ iff $H_f(a)\prec/\succ0$. This follows from Taylor's theorem above.
	- **Conditional extremum**: to find the extremum of $f(x_1,\cdots,x_{m+n})$ given $$g=(g_i(x_1,\cdots,x_{m+n}))^T=0,\quad 1\le i\le m$$We consider the **Lagrange multiplier**: construct $$F(x_1,\cdots,x_{m+n})=f(x_1,\cdots+x_{m+n})+\sum_j\lambda_jg_j(x_1,\cdots,x_{m+n})$$the the extremum must be one of the solutions of the system $$\nabla F=0\quad\iff\quad\frac{\partial F}{\partial x_i}=\frac{\partial F}{\partial \lambda_j}=0$$**Intuition**: denote $G_i=\set{g_i=0}$. Intuitively when the conditional extremum $f(x_0)$ is reached the corresponding level set $M=\set{f=f(x_0)}$ is tangent to the domain specific by $G=\bigcap G_i$. Now that $T_{x_0}G=\bigcap T_{x_0}G_i$, by [[Hilbert Space#Closed subspace]] we have $$T_{x_0}G\subset T_{x_0}M\quad\iff\quad\nabla f\in\span(\nabla g_i)\quad\Longrightarrow\quad\nabla\left(f-\sum\lambda_i g_i\right)=0$$where $\lambda_i\in\mathbb R$ are constants. This yields $\partial F/\partial x_i=0$, while $\partial f/\partial \lambda_j=0$ follows naturally from the constraints. The final expression $\nabla F=0$ is just a compact way to writing it.
		- **Generalization**: this can be generalized to the KKT condition, which is discussed in detail in [[Nonlinear Programming]].
## Gradient
The gradient of $f:\mathbb R^n\to\mathbb R$ is defined as $$\nabla =\begin{bmatrix}\frac{\partial }{\partial x_1}\\\vdots\\\frac{\partial }{\partial x_n}\end{bmatrix},\quad\nabla f=\begin{bmatrix}\frac{\partial f}{\partial x_1}\\\vdots\\\frac{\partial f}{\partial x_n}\end{bmatrix}$$The local linear approximation in this case is $f(x+\Delta x)=f(x)+\nabla f(x)^T\Delta x+o(\Delta x)$.
- **Divergence & Curl**: define $\operatorname{div}f=\nabla\cdot f,\operatorname{curl}f=\nabla\times f$.
- **Algebraic operations**
	- **Product**: $\nabla(fg)=f\nabla d+g\nabla f$.
	- **Chain rule**: similar to the case of single variable, we have $$\nabla(f\circ g)(c)=\Big(J_g(c)\Big)^T\nabla f(a)$$where $a=g(c)$, and $J_g$ the Jacobian matrix. 
- **Directional derivative**: given $\|v\|=1$ we define $$\frac{\partial f}{\partial v}(x)=\lim_{t\to0}\frac{f(x+t v)-f(x)}{t}$$By denoting $v=(v_1,\cdots,v_n)$ and use a difference telescoping we can verify that $$\frac{\partial f}{\partial v}=\braket{\nabla f,v}$$which is useful in many cases.
- **Laplace operator**: define $$\Delta=\nabla\cdot\nabla,\quad\Delta f=\nabla\cdot\nabla f=\sum_i\partial_{ii}f$$Arithmetic properties of this operator can be derived directly from definition. More can be found in [[Harmonic function]].
## Vector-valued: $f:\mathbb R^n\to\mathbb R^m$
In this case the gradient become a matrix, called the **Jacobian matrix** $$J_f=\begin{bmatrix}\frac{\partial f}{\partial x_1}&\cdots&\frac{\partial f}{\partial x_n}\end{bmatrix}=\begin{bmatrix}\frac{\partial f_1}{\partial x_1}&\cdots&\frac{\partial f_1}{\partial x_n}\\\vdots&\ddots&\vdots\\\frac{\partial f_m}{\partial x_n}&\cdots&\frac{\partial f_m}{\partial x_n}\end{bmatrix}$$The local linear approximation is $f(x+\Delta x)=f(x)+J_f(x)^T\Delta x+o(\Delta x)$.
- **Algebraic operations**
	- **Chain rule**: we have $J_{f\circ g}(x)=J_f(g(x))J_g(x)$.
- **Increment theorem**: for $E\subset\mathbb R^n$ convex and $f:E\to\mathbb R^m$ differentiable, if $\sup_E\|J_f\|=M$ then $$\|f(y)-f(x)\|\le M\|y-x\|$$This can be shown intuitively by contradiction via repetitively pick subintervals from $[x,y]$ with the property $\|f(y^{(k)})-f(x^{(k)})\|>M\|y^{(k)}-x^{(k)}\|$.
- **Inverse function theorem**: for $m=n$ if $f\in C^1(E)$ with $\det J_f(a)\neq0$, then there exists neighborhood $U$ of $a$ s.t. $f|_U$ is bijective and has an inverse $g$ with $$J_g(y)=J_f(x)^{-1}\quad\text{where}\quad y=f(x)$$**Proof**: WLOG assume that $f(0)=0,J_f(a)=I$ (since $g^{-1}=L^{-1}\circ f\iff g\circ L^{-1}=f^{-1}$), then by continuity of norm w.r.t each entry ([[Matrix]]) for any $\varepsilon>0$ there exists $\delta>0$ s.t. $$\|J_f-I\|\le\varepsilon,\quad\forall x\in U=B_\delta(0)$$Now that $J_{f-x}=J_f-I$ we have $$|(f(x_1)-x_1)-(f(x_2)-x_2)|\le\varepsilon|x_1-x_2|\Longrightarrow|f(x_1)-f(x_2)|\ge(1-\varepsilon)|x_1-x_2|,\quad\forall x_1,x_2\in U$$by piking $\varepsilon<1$ we know that $f$ is injective, hence $f|_U$ is bijective. Denote $f(U)=V,$ and let $g:V\to U$ be its inverse. Now $g$ is also continuous (by the domination above), hence $V$ is also open, and we can directly verify that $J_g=J_f^{-1}$, which also implies $g\in C^1(V)$.
	- **Intuition**: the key idea is linearization. $\det J_f$ ensures no vector vanishes under $f$, while $J_f=I$ together with its continuity ensures that in a neighborhood of $0$ it behaves "like" an identity, hence injective. The rest follows naturally.
- **Implicit function theorem**: for $f:\mathbb R^{m+n}\to\mathbb R^m,f\in C^1,f(a,b)=0$, write $J_f=\begin{bmatrix}\frac{\partial f}{\partial x}&\frac{\partial f}{\partial y}\end{bmatrix}$, if $\det\frac{\partial f}{\partial y}\neq0$ then there exists neighborhoods $U,V$ of $a,b$ and a unique $g:U\to V$ s.t. $g(a)=b,f(x,g(x))=0$, with $$J_g(x)=-\left(\frac{\partial f}{\partial y}(x,g(x))\right)^{-1}\frac{\partial f}{\partial x}(x,g(x))$$**Proof**: define $$F(x,y)=\begin{bmatrix}x\\ f(x,y)\end{bmatrix}\quad\Longrightarrow\quad J_F=\begin{bmatrix}I_n &0\\\frac{\partial f}{\partial x}&\frac{\partial f}{\partial y}\end{bmatrix}$$hence $\det J_F\neq0$, thus we can apply the inverse function theorem to construct $G=F^{-1}$ on $W=U\times V$ that preserves $x$. Now notice that $$\begin{bmatrix}x\\y\end{bmatrix}=F\begin{bmatrix}G_1(x,y)\\G_2(x,y)\end{bmatrix}=\begin{bmatrix}x\\f(x,G_2(x,y))\end{bmatrix}$$Hence $y=f(x,G_2(x,y))\Longrightarrow f(x,G_2(x,0))=0$. We can directly verify that $G_2(x,0)$ is the unique implicit function given by $f$, satisfying all the properties above. 
	- **Intuition**: $\det\partial_yf\neq0$ ensures that $y$ behaves quite "regularly" within the level set $f=0$. Under this condition we can solve $y$ using $x$.