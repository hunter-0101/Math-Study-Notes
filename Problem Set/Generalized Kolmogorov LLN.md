> For a [[Measure]] space $(X,\Sigma,\mu)$ and a sequence of uniformly essentially bounded functions $f_n$, denote the average as $\overline f_n=\frac{1}{n}\sum_{i=1}^n f_i$, then $$\sum_{n\ge1}\frac{1}{n}\int_X|\overline f_n|^2d\mu<\infty\quad\Longrightarrow\quad\overline f_n\xto{\ae}0$$
## Direct characterization of a.e. convergence
By [[Measurable Function]] the set of points at which $\overline f_n$ fails to converge to $0$ can be written as $$D=\bigcup_{k=1}^\infty\bigcap_{n=1}^\infty\bigcup_{t\ge n}\Set{\left|\overline f_t\right|>\frac{1}{k}}$$We consider its contrapositive. Assume that $\mu(D)=2\delta>0$, then by continuity of [[Measure]] there exists some $K\in\mathbb N$ s.t. $$\mu\left(\bigcap_{n=1}^\infty\bigcup_{t\ge n}\Set{\left|\overline f_t\right|>\frac{1}{k}}\right)>\delta,\quad\forall k\ge K\tag{1}$$We pick any specific $k\ge K$ and denote the above set as $A$. At the first glance it seems like we're stuck here: the above inequality is not sufficient for the desired results, e.g., consider $$\overline f_t=\begin{cases}\chi_{[0,1]},&t=2^s,s\in\mathbb N\\0,&\text{otherwise}\end{cases}$$However such counterexample is not valid, since by $f_n=n\overline f_n-(n-1)\overline f_{n-1}$ it's obvious that uniformly essential boundedness is violated. From this fact we're reminded that condition on $f_n$ implies more than boundedness of $\overline f_n$. Assume that the uniform essential supremum is $M$, then $$\left|\overline f_{n+m}-\overline f_n\right|=\left|\frac{\sum_{i=1}^{n+m}f_i}{n+m}-\frac{\sum_{i=1}^nf_i}{n}\right|=\left|\frac{n\sum_{i=1}^mf_{n+i}-m\sum_{i=1}^nf_i}{n(n+m)}\right|\le\frac{2mM}{n+m},\quad\forall n,m\in\mathbb N\tag{2}$$Now it suffices to combine this slow-variation condition $(2)$ with $(1)$ to show divergence of the series. Below we denote $\varepsilon=\frac{1}{k}$, and notice that $$\frac{2mM}{n+m}\le\frac{\varepsilon}{2}\quad\iff\quad m\le\frac{n\varepsilon}{4M-\varepsilon}$$Denote $m_n=\floor{\dfrac{n\varepsilon}{4M-\varepsilon}}$. Now for any $x\in\bigcap_{n=1}^\infty\bigcup_{t\ge n}\Set{\left|\overline f_t\right|>\varepsilon}$ by $(1)$ there exists infinitely many $n_i\in\mathbb N$ s.t. $\overline f_n(x)>\varepsilon$. It's obviously possible to pick a subsequence $n_i'$ that is sparse enough, in the sense that $n_{i+1}'>n_i'+m_{n_i'},\forall i\in\mathbb N$. Now we set $$J_i=\set{n_i'+1,\cdots,n_i'+m_{n_i'}}\quad\Longrightarrow\quad f_{j}(x)\ge\frac{\varepsilon}{2},\quad\forall j\in J_i$$Notice that the sum over one such block is $$\begin{align}\sum_{j\in J_i}\frac{|\overline f_j(x)|^2}{j}&>\sum_{j=n_i'+1}^{n_i'+m_{n_i'}}\frac{(\varepsilon/2)^2}{j}=\frac{\varepsilon^2}{4}\sum_{j=n_i'+1}^{n_i'+m_{n_i'}}\frac{1}{j}\\&>\frac{\varepsilon^2}{4}\cdot m_{n_i'}\cdot\frac{1}{n_i'(1+\varepsilon/4M)}&\text{since }j\le n_i'+m_{n_i'}\\&\ge\frac{\varepsilon^2}{4}\left(\frac{n_i'\varepsilon}{4M}-1\right)\frac{1}{n_i'(1+\varepsilon/4M)}\\&=\frac{\varepsilon^2}{4(1+\varepsilon/4M)}\left(\frac{\varepsilon}{4M}-\frac{1}{n_i'}\right)\\&\to\frac{\varepsilon^3}{16M+4\varepsilon}>0,&i\to\infty\end{align}$$Denote the constant in the last line as $C$, then as $i\to\infty$ the summation over $J_i$ is bounded by, say, $C/2$. Since there are infinitely many $J_i$, the overall summation equals $\infty$. Returning to the original expression, by Tonelli's theorem ([[Measure]]) we have $$\sum_{n=1}^\infty\frac{1}{n}\int_X |\overline f_n|^2d\mu=\int_X\left(\sum_{n=1}^\infty\frac{|\overline f_n(x)|^2}{n}\right)d\mu\ge\int_A\left(\sum_{i=1}^\infty\sum_{j\in J_i}\frac{|\overline f_j|^2}{j}\right)d\mu=\int_A\infty d\mu=\infty$$which is a contradiction.
## Borel-Cantelli characterization
Borel-Cantelli lemma provides a sufficient condition for $\ae$ convergence ([[Measurable Function]]), and we consider to apply it to this problem. The simplest way to associate them is $$D_{n,\varepsilon}=\set{|\overline f_n|>\varepsilon}\quad\Longrightarrow\quad\mu(D_{n,\varepsilon})\le\frac{\int_X|\overline f_n|^2d\mu}{\varepsilon^2}$$by a Chebyshev-like estimation ([[Central Limit Theorem]]), but this is obvious insufficient. At this point we again notice the extra slow-variation condition $(2)$ with $m=1$, and consider the dyadic decomposition ([[Estimation]]): $$I_k=[2^k,2^{k+1}),\quad F_k=\max_{n\in I_k}|\overline f_n|,\quad G_k=\frac{1}{|I_k|}\sum_{n\in I_k}|\overline f_n|^2$$then still by the Chebyshev-like estimation we get $$E_{k,\varepsilon}=\set{|G_k|>\varepsilon}\quad\Longrightarrow\quad\mu(E_{k,\ \varepsilon})\le\frac{1}{\varepsilon}\int_XG_kd\mu$$By summing over $k\in\mathbb N$ we get $$\sum_{k=1}^\infty\mu(E_{k,\varepsilon})\le\frac{1}{\varepsilon}\sum_{k=1}^\infty\frac{1}{|I_k|}\int_X\sum_{n\in I_k}|\overline f_n|^2d\mu=\frac{1}{\varepsilon}\sum_{n\in\mathbb N}\frac{2}{n}\int_X|\overline f_n|^2d\mu=\frac{2}{\varepsilon}\sum_{n\in\mathbb N}\frac{1}{n}\int_X|\overline f_n|^2d\mu<\infty$$where we still used Tonelli's theorem for adjusting order of summation and integration. Now the above inequality for arbitrary $\varepsilon>0$ shows that $G_k\xto\ae0$, and it remains to somehow bound $F_k$ with $G_k$, which is quite simple: denote $E_k=\set{n\in I_k:|\overline f_n|>F/2}$, then we have $$G_k\ge\frac{1}{2^k}\sum_{n\in E_n}|\overline f_n|^2\ge\frac{1}{2^k}\cdot\frac{F^2}{4}|E_k|\ge\frac{|F|^3}{16M}$$hence $F\xto\ae0$, which further implies $\overline f_n\xto\ae0$ by a simple $\varepsilon$-$N$ argument. 