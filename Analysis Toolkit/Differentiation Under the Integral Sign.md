Sometimes when calculating the integral of a complex function, we may notice that the function itself can be derived through differentiating a simple function multiple times (w.r.t some other variables). This idea can be formalized into differentiation under the integral sign:$$\frac{d}{dt}\int_a^bf(x,t)dx=\int_a^b\frac{\partial}{\partial t}f(x,t)dx$$and is theoretically supported by the **Leibniz integral rule**, which can be seen as a continuous version of termwise differentiation ([[Function on Euclidean Space]]). This method is also known as **Feynman's trick**.
- **Elementary calculus version**: given $f(x,t)$ s.t. both $f(x,t),f_t(x,t)$ are continuous in $x,t$ within the integral domain, and assume that $a(t),b(t)\in C^1$, then we have$$\frac{d}{dt}\left(\int_{a(t)}^{b(t)}f(x,t)dx\right)=f(x,b(t))\cdot\frac{d}{dt}b(t)-f(x,a(t))\cdot\frac{d}{dt}a(t)+\int_{a(t)}^{b(t)}\frac{\partial}{\partial t}f(x,t)dx$$**Proof**: the case of constant bounds can be established by the Fubini's theorem:$$\int_t^{t+h}\int_a^b f_t(x,s)dxds=\int_a^b \int_t^{t+h} f_t(x,s)dsdx= \int_a^b f(x,t+h)dt - \int_a^b f(x,t)dt$$Now divide $h$ and let $h\to0$, then the desired result follows from mean value theorem and continuity of integral ([[Integral Calculus on Euclidean Space]]). With chain rule we can prove the variable bounds form.
- **Measure theoretic version**: for open $X\subset\mathbb R$ and measure space $\Omega$, if $f:\Omega\times X\to\mathbb R$ is Lebesgue integrable given $t\in X$, and the derivative $\partial_tf(\omega,t)$ exists everywhere for almost all $t\in X$, with a dominating integrable function $\Theta:\Omega\to\mathbb R$ s.t. $|\partial_tf(\omega,t)|\le\Theta(\omega),\forall t\in X$, then $$\frac{d}{dt}\int_\Omega f(\omega,t)d\omega=\int_\Omega\frac{\partial}{\partial t}f(\omega,t)d\omega$$The proof is essentially the same as the above, with existence of dominating function ensuring validity of Fubini's theorem ([[Lebesgue Integral]]) and differentiability of parametrized integral via uniform convergence ([[Function on Euclidean Space]]).
	- **Weaker condition**: we may assume $f$ to be only jointly measurable, integrable over $\Omega$ for almost all $t\in X$, and is AC of $t$ (to ensure Lebesgue FTC), and further the derivative is locally integrable.
- **Discussion on conditions**: several examples are listed below illustrating necessity of each condition:
	- **Uniform convergence**: without uniform convergence the parametrized integral might not even be continuous, e.g. $f(x,t)=te^{-|t|x}$, which satisfies $\int_{0}^\infty f(x,t)dx=\sgn t$.
	- **Local integrability**: the convolution of fundamental solution of [[Laplace's Equation]] with $f\in C_c$ fails to satisfy Laplace's equation via differentiability property of [[Convolution]] because $\Phi(x)$ is not locally integrable near $0$, 
The main idea behind differentiation under the integral sign is to make use of the **change of variable to introduce a new parameter**. Usually we choose $x=tx$ (or some other forms considering the specific function we wanna integrate), and move the extra coefficient to the other side (whose validity is guaranteed by the parametric nature).
## Application
The key idea is that, when trying to create the target integrand we'll first treat the variable $x$ as fixed parameter, and introduce a new variable $t$, s.t. after differentiating w.r.t. $t$ the derivative would yield some desired expression concerning $x$.
- Find the value of $$\phi(s)=\int_0^{+\infty}\frac{\ln(1+sx^2)}{x(1+x^2)}dx$$In this case the parameter already exists, thus we only need to directly take a differentiation and then integrate. Notice that $$\frac{d}{ds}\phi(s)=\int_0^{+\infty}\frac{\partial}{\partial s}\cdot\frac{\ln(1+sx^2)}{x(1+x^2)}dx=\int_0^{+\infty}\frac{x}{(1+x^2)(1+sx^2)}dx=\frac{\ln s}{2(s-1)}$$now substitute $1-s$ with $s$ and expand the $\ln s$ with Taylor series would yield the answer.
- **Euler's integral**: to find $\Gamma(n)=\int_0^\infty x^{n-1}e^{-x}dx$ ([[Gamma Function]]) for $n\in Z$, consider $$\int_0^\infty e^{-tx}=\frac{1}{t}\quad\Longrightarrow\quad\int_0^\infty x^ne^{-tx}dx=\frac{n!}{t^{n+1}}$$now set $t=1$ and we get $\int_0^\infty x^ne^{-x}=n!$. Note that the above $\int_0^\infty e^{-tx}=\frac{1}{t}$ is also commonly used as a trick for substituting $\frac{1}{t}$ to introduce a new parameter.
- **Gaussian integral**: to find the integral $$I=\int_0^\infty e^{-x^2/2}dx$$we set $$F(t)=\int_0^\infty\frac{e^{-t^2(1+x^2)/2}}{1+x^2}dx\quad\Longrightarrow\quad F(0)=\frac{\pi}{2},\quad F(\infty)=0$$Meanwhile, by differentiation we get $$F'(t)=-te^{-t^2/2}\int_0^\infty e^{-(tx)^2/2}dx\quad\xRightarrow{y=tx}\quad F'(t)=-e^{-t^2/2}\int_0^\infty e^{-y^2/2}dy=-Ie^{-t^2/2}$$Integrate both sides on $[0,\infty)$, then we get $I^2=\pi/2\Rightarrow I=\sqrt{\pi/2}$.
	- **Why not $e^{-tx^2/2}$**: if we add a $t$ at the exponent after differentiation we'll get $x^2e^{-x^2}$, which cannot be integrated either.
	- **Higher moments of Gaussian**: given that Gaussian integral is known, notice that $$\int_\mathbb R e^{-tx^2/2}dx=\frac{\sqrt{2\pi}}{\sqrt t}\quad\xRightarrow{\frac{d^n}{dt^n}}\quad\int_\mathbb Rx^ne^{-tx^2/2}dx=\frac{(n-1)!!}{t^{(n+1)/2}}\sqrt{2\pi},\quad\forall 2\mid n$$Although the odd $n$ case cannot be computed in this way.
## Discussion under [[Distribution]] theory
In distribution theory, **derivatives are not taken pointwise**, but rather **via integration against test functions**, by moving the differentiation onto the test function using integration by parts. Hence identities of the form $$L_t\int f(x,t)dx=\int L_tf(x,t)dx$$is always valid in distribution sense, since that's exactly how derivative is defined. Several examples are provide below.
1. **Green's function method**: in [[Variation of Parameters]] we interpret the differentiation $L\phi_p$ in the distributional sense: $$\braket{L\phi,\psi}=\braket{\phi,L^*\psi}=\int\phi(t)L^*\psi(t)dt=\int\left(\int f(s)G(t,s)ds\right)L^*\psi(t)dt$$Here we assume that the integral is Fubini-valid ([[Measure]]), hence $$\braket{L\phi,\psi}=\int f(s)\left(\int G(t,s)L^*\psi(t)dt\right)ds=\int f(s)\braket{G(\cdot,s),L^*\psi}ds=\braket{f,s\mapsto\braket{LG(\cdot,s),\psi}}$$which gives meaning to applying $L$ under the integral.
2. **Approximation to $\sgn x$**: consider the example mentioned above: $x\in[0,\infty),t\in[-1,1]$, and $$f(x,t)=te^{-|t|x}\quad\Longrightarrow\quad\int_0^\infty f(x,t)dx=\sgn t$$Meanwhile, by differentiation w.r.t $t$ we get $$\frac{\partial}{\partial t}f(x,t)=e^{-|t|x}-tx\sgn(t)e^{-|t|x}$$while integrating the expression on $[0,\infty)$ would yields a singularity at $t=0$, in distribution sense we have instead $$\int_0^\infty\frac{\partial}{\partial t}f(x,t)dx=2\delta(t)$$this of course makes sense, since $\frac{d}{dt}\sgn(t)=2\delta(t)$.