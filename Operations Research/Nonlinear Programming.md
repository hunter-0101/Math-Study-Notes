A **nonlinear programming (NLP)** problem is an optimization problem of the form $$\begin{array}{l}\max& f(x)\\\text{s.t.}&g_i(x)\le 0,\forall i\\&h_j(x)=0,\forall j\\&x\in X\end{array}$$depending on the **constraint set**, a problem might be **feasible**, **infeasible**, or **unbounded**, as in [[Linear Programming]].
- **Global & local optimum**: we say that $x^*$ is a **global optimum** of an NLP problem if $$f(x^*)\le f(x),\quad\forall x\in X$$and a **local optimum** if the above holds in some neighborhood of $x$ in $X$. It's **strict** if the inequality is strict.
- **Discussion**: in [[Differential Calculus on Euclidean Space]] we've already discussed the method of Lagrange multiplier, but its application is limit to a very small set of problems, because it requires to solving a higher dimensional [[Linear ODE System]]. It's for this reason that we need to find other numerical methods for solving NLP problem more easily.
- **Iterative method**: an iterative method is defined by $$x^{k+1}=\Psi(x^k),\quad\forall k\ge0$$in NLP the most common form of $\Psi$ is $\Psi(x)=x-tp^k$ where $t$ is the **step length**, and $p^k$ is the **descent direction**. More discussion in this topic can be found in [[Iterative Method]]. 
## Convex optimization
See [[Convexity]] for basic definition on convex set and functions.
A NLP is referred to a **convex programming (CP)** problem if the constraint set $$X=\set{x:g_i(x)\le0,h_j(x)=0,\forall i,j}$$is convex, and $f$ is convex over $X$.
- **Criterion for CP**: if $g_i$ are convex and $h_j$ are linear, while $f$ is convex over $X$, then the above problem is an CP problem. The proof is straightforward.
	- To verify whether any $g_i$ is convex we'll usually look at its Hessian matrix, as discussed in [[Convexity]].
- It's obvious that in an CP problem, local optimum is equivalence to global optimum.
## Line search
A NLP problem with only $1$ variable is called a **line search problem**. Below we discuss two different methods for line search.
- **Golden-section search**: fora a **unimodal function** (one with only one decreasing domain on the left, and increasing domain on the right), we can search for its minimum by iteratively decrease the search domain. If initially we're given $[a,b]$, then the iteration proceeds by $$t_1=b-\omega(b-a),\quad t_2=a+\omega(b-a)\where\omega\approx0.618$$if $f(t_1)<f(t_2)$, while $t_2-a<\varepsilon$ a given precision, then we halt and output $f(t_1)$. Otherwise we perform a symmetric operation, and output. If the precision is not reached, we replace $$a\gets t_1,\quad b\gets t_2$$and repeat until the precision is reached.
	- **Tableau for golden-section search**: a typical solution tableau is like $$\begin{array}{c|cc}\text{iteration}&a&b&t_1&t_2&\varphi_1&&\varphi_2&\act a&\act b\\\hline 1&0.5&3.5&1.646&2.354&-0.783&>&-0.961&\circ\\2&1.646&3.5&2.354&2.792&-0.961&<&2.649&&\circ\\3&1.646&2.792&2.084&2.354&-1,938&<&-0,961&&\circ\end{array}$$after 3 iterations we verify that $t_2-a=0.71<\varepsilon=0.8$, hence we terminate and output $t_1=2.084$.
- **Newton's method**: for $f\in C^2([a,b])$ with $f''\neq0$, we proceeds as in the [[Numerical ODE]] - given an initial point $t_k$, we replace $f$ with the second order Taylor expansion $$g(x)=f(t_k)+f'(t_k)(x-t_k)+\frac{f''(t_k)}{2}(x-t_k)^2$$and use the minimum of $g(x)$ to update $t_{k+1}$: $$t_{k+1}=t_k-\frac{f'(t_k)}{f''(t_k)}$$this repeats until $|f'(t_k)|<\varepsilon$ a halting error. 
	- **Tableau for Newton's method**: a typical solution tableau is like $$\begin{array}{c|cc}k&t_k&\varphi'(t_k)&1/\varphi''(t_k)\\\hline1&6&344&1/276\\2&4.7536&85.4625&1/145.0762\\3&4.1645&14.8134&1/96.1715\\\vdots&&\vdots\end{array}$$
## Unconstrained problem
To solve the unconstrained problem $$\min f(x)\where f\in C^1$$several lemmas are useful:
- **Descent direction**: and $p$ with $\nabla f\cdot p<0$ is a descent direction. This follows from the Taylor's theorem.
- **Local optimum**: if $x_0$ is a local optimum ,then $\nabla f(x_0)=0$.
- **Strict local optimum**: if $\nabla f(x^*)=0,H_f\succ0$, then $x^*$ is a strict local optimum.
Below we describe two different methods for solving unconstrained optimization problems.
- **Method of gradient descent**: in each step we pick $p^k=-\nabla f(x^k)$ , and find a proper step length $t$ to proceed. This repeats until $\|\nabla f(x^k)\|\le\varepsilon$.
	- **Step length**: in general this can be done via line search, as discussed above. However in many cases we can analytically calculate it via differentiation.
	- **Sawtooth phenomenon**: notice that in gradient descent we have $$\begin{cases}\dfrac{d}{dt}f(x^k+t_kp^k)=0\\p^k=-\nabla f(x^k)\end{cases}\quad\Longrightarrow\quad\nabla f(x^{k+1})\cdot\nabla f(x^k)=0$$hence we can observe a **sawtooth phenomenon**: the optimization path is zigzag rather than heading towards the optimum. 
- **Conjugate gradient (F-R) method**: consider $A\in S^n(\mathbb R)$. $p,q\in\mathbb R^n$ are **$A$-conjugate** if $$p^TAq=0$$and $\set{p_i}$ is a set of **$A$-conjugate vectors** if they're pairwise $A$-conjugate. For $A\in S^n_{++}(\mathbb R)$ we can verify easily that a set of $A$-conjugate vectors are linearly independent, since otherwise $$\sum_{i=1}^n\alpha_ip_i=0\quad\Longrightarrow\quad 0=\left(\sum_{i=1}^n\alpha_ip_i\right)^TA\left(\sum_{i=1}^n\alpha_ip_i\right)=\sum_{i\neq j}p_i^TAp_j+\sum_{i=1}^np_i^TAp_i>0$$which is a contradiction. We have the known result that, for $$\min f(x)=\frac{1}{2}x^TAx+b^Tx+c\where A\in S^n_{++}(\mathbb R)$$and any set of $A$-conjugate vectors $p_i,0\le i\le n-1$, starting from any $x_0\in\mathbb R^n$, then at most $n$ iterations is required to find the global optimum via precise line search if we go along $p_i$ at $i$-th step. This is referred to as a **method of conjugate directions**, and if the directions are chosen based on gradients then we call it a **method of conjugate gradients**. The overall procedure of this method is like:
	1. **Initial step**: starting from $x_0$ we pick $p^0=-\nabla f(x_0)$.
	2. **Iteration**: by line search we find $t^0$ and get $x^1=x^0+t^0p^0$. The next direction is $$p^1=-\nabla f(x^1)+\lambda_0p^0$$where $\lambda_0$ should be chosen that $p^0,p^1$ are $A$-conjugate. By calculation we have $$\lambda_0=\frac{(p^0)^TA\nabla f(x^1)}{(p^0)^TAp^0}$$in general, if $p^0,\cdots,p^k$ are known, then next direction is $$p^{k+1}=-\nabla f(x^{k+1})+\lambda_kp^k\where\lambda_k=\frac{(p^k)^TA\nabla f(x^{k+1})}{(p^k)^TAp^k}$$We can actually simplify this further into $$\begin{cases}p^0=-\nabla f(x^0)\\p^{k+1}=-\nabla f(x^{k+1})+\lambda_kp^k\\\lambda_k=\dfrac{\|\nabla f(x^{k+1})\|^2}{\|\nabla f(x^k)\|^2}\end{cases}$$This is usually called the **Fletcher-Reeves formula**, and this method is the F-R method.
## Constrained problem
In this section we consider algorithms for solving constrained problems $$\begin{array}{l}\max& f(x)\\\text{s.t.}&g_i(x)\le 0,\forall i\\&h_j(x)=0,\forall j\end{array}$$whose **feasible domain** is $X=\set{x:g_i(x)\le0,h_j(x)=0,\forall i,j}$.
**Karush-Kuhn-Tucker (KKT)Â conditions**: by reasoning similar to the method of Lagrange multiplier in [[Differential Calculus on Euclidean Space]] we can show that for any $x^*$ a local optimum there exists $\lambda_i,\mu_j\in\mathbb R$ s.t. $$\begin{cases}\nabla_x\left(f(x^*)+\displaystyle\sum_{i}\lambda_ig_i(x^*)+\displaystyle\sum_j\mu_jh_j(x^*)\right)=0\\\lambda_i\ge0\end{cases}$$Moreover, if $g_i$ are differentiable at $x^*$, we can add in another condition $\lambda_ig_i(x^*)=0$.

In addition to the KKT condition, another commonly used method is the **penalty method**.
- **Exterior penalty function**: the main idea is that we may construct some $p(x)$ that increases dramatically outside $X$, and consider to solve the unconstrained problem $$\min F(x)=f(x)+p(x)$$here $p$ is referred to as the interior penalty function. A rule of thumb for choosing $p$ is $$p_c(x)=c\sum_{i}\left(\max(g_i(x),0)\right)^2+\frac{c}{2}\sum_jh_j^2(x)$$here $c$ is the **penalty factor**. In practical cases we'll usually pick a sequence $c_k$ and solve the corresponding minimization problem $$\min F_{c_k}=f(x)+p_{c_k}(x)$$and we would expect that the optimum proxy would converge to its true value.
- **Interior penalty function**: the main idea is that we could pick some boundary penalty $B(x)$ that explodes on the boundary of the feasible domain, so that the feasible solutions are naturally bounded within the feasible domain. A rule of thumb for picking $B$ is $$B_{d_k}(x)=-d_k\sum_i\frac{1}{g_i(x)}\quad\text{or}\quad B_{d_k}(x)=-d_k\sum_i\ln(-g_i(x))$$where $d_k$ is the sequence of **penalty factors**. 
