A linear system of [[First Order ODE]] is of the form $$\frac{dx}{dt}=Ax+b\quad\text{where}\quad x(t)=\begin{bmatrix}x_1(t)\\\vdots\\x_n(t)\end{bmatrix},A(t)=[a_{ij}(t)]_{n\times n},b(t)=\begin{bmatrix}b_1(t)\\\vdots\\b_n(t)\end{bmatrix}$$Here $x_i,a_{ij},b_i$ are all functions from $\mathbb R$ to $\mathbb R$.
- **Existence and uniqueness theorem**: by Picard-Lindelöf theorem applied on $f(t,x)=Ax+b$ ([[First Order ODE]]) we get the existence and uniqueness of solution for linear system IVP.
## Fundamental set of solutions
Consider the homogeneous system $x'=Ax$. By Picard-Lindelöf theorem a solution is fully determined by its initial value $x_0\in\mathbb R^n$, hence the map from solution space $\mathfrak S_A$ to $\mathbb R^n$ given by $$T:\mathfrak S_A\to\mathbb R^n,\quad x=\phi(t)\mapsto x_0=\phi'(t_0)$$is a [[Vector Space]] isomorphism. We define a **fundamental set of solutions** as a set of $n$ linearly independent solutions $\phi_i$, with corresponding **fundamental matrix**$$\Phi(t)=[\phi_1(t),\cdots,\phi_n(t)]$$It's obvious that $\Phi'=A\Phi$, and given $C\in\gl(n,\mathbb R)$ for initial value conditions we have $\Psi(t)=\Phi(t)C$ for the corresponding fundamental matrix. [[Matrix]]
- **Wronskian**: for a set of solutions $\phi_i=(\phi_{1i},\cdots,\phi_{ni})^T$, define its Wronskian by $$W(t)=\begin{vmatrix}\phi_1(t)&\phi_2(t)&\cdots&\phi_n(t)\end{vmatrix}$$then $x_i$ are linearly dependent iff $W(t)\equiv0,\forall t\in[a,b]$.
- **Liouville's formula**: assuming that $\tr A$ is continuous, for a set of solutions $\phi_i$ we have $$W(t)=W(t_0)\exp\left(\int_{t_0}^t\tr A(s) ds\right)$$**Proof**: by Leibniz formula for [[Determinant]] and product rule for [[Differential Calculus on Euclidean Space]] we have that $$W'(t)=\sum_{i=1}^n\begin{vmatrix}\phi_{11}&\phi_{12}&\cdots&\phi_{1n}\\\vdots&\vdots&&\vdots\\\phi_{i1}'&\phi_{i2}'&\cdots&\phi_{in}'\\\vdots&\vdots&&\vdots\\\phi_{n1}&\phi_{n2}&\cdots&\phi_{nn}\end{vmatrix}(t)=\sum_{i=1}^n\begin{vmatrix}\phi_{11}&\phi_{12}&\cdots&\phi_{1n}\\\vdots&\vdots&&\vdots\\a_{ii}\phi_{i1}&a_{ii}\phi_{i2}&\cdots&a_{ii}\phi_{in}\\\vdots&\vdots&&\vdots\\\phi_{n1}&\phi_{n2}&\cdots&\phi_{nn}\end{vmatrix}(t)=\tr A(t)W(t)$$where the second equality is justified by $$(\phi_{i1}',\cdots,\phi_{in}')=\sum_{j=1}^na_{ij}(\phi_{j1},\cdots,\phi_{jn}),\quad\forall1\le i\le n$$By solving this [[First Order ODE]] we get the formula.
## Homogeneous equations with constant coefficients
For homogeneous linear system of the form $$x'=Ax,\quad A\in M_n(\mathbb R)$$by similarity of fundamental matrix under vector space isomorphism discussed above it suffices to only discuss the [[Jordan Normal Form]] $PAP^{-1}=J$, since any solution can be obtained via $$x'=P^{-1}J Px\quad\iff\quad(Px)'=J(Px)$$Hence by solving $\phi'=J\phi$ we can reconstruct $x$ via $x=P^{-1}\phi$.
- Eigenvalue $\lambda_i$ with $a_i=g_i$: denote the corresponding eigenvector as $\alpha_j$, then its contribution to the solution is $x=\sum_j c_j\alpha_je^{\lambda_it}$.
	- **Complex eigenvalue**: similarly, complex eigenvalues can be decomposed using Euler's formula, and its real and imaginary parts are both solutions.
- $\lambda_i$ with $a_i>g_i$: consider a Jordan block $J$, then we have $(Px)'=J(Px)$ with $P$ consisting of generalized eigenvectors. In this case the solution will be of the form $$x_j=\sum_{k=1}^j(\alpha_k+t\alpha_{k-1}+\cdots+\frac{1}{k!}t^k\alpha_1)e^{\lambda t},\quad1\le j\le a_i$$where $\alpha_k$ is the $k$-th generalized eigenvalue in the Jordan chain. [[Eigendecomposition]]
Note that general formula can also be obtained via **[[Matrix]] exponential**: we have $$\Phi'=A\Phi\quad\Longrightarrow\quad \Phi(t)=\exp(At)$$This is because $\frac{d}{dt}\exp(At)=A\exp(At)$.