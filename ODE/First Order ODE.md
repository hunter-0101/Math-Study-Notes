The general form of first order ODE is of the form $$F(y',y,x)=0$$where $F$ is an arbitrary function. We'll mainly look at ODE of the forms $P(x)y'+Q(x)y=G(x)$ or $y'=f(x,y)$.
## Picard-Lindelöf theorem
**Theorem**: consider $D\subset\mathbb R\times\mathbb R^n$ a closed rectangle with $(x_0,y_0)\in\operatorname{int}D$. Let $f:D\to\mathbb R^n$ be continuous in $x$ and Lipschitz continuous in $y$  with Lipschitz constant $L$ ([[Function on Euclidean Space]]), then there exists an interval $|x-x_0|\le\delta$ on which a unique solution $y=\phi(x)$ exists for the initial value problem $$y'=f(x,y),\quad y(x_0)=y_0$$**Proof**: pick an proper $\delta$ s.t. $\delta L<1$, and the domain of definition is restricted to $$D_\delta=I(x_0,\delta)\times B(y_0,\delta L)\subset D$$Now consider the space $\mathcal X=C(I(x_0,\delta), B(y_0,\delta L))$, and define the **Picard operator** $$\Gamma: \mathcal X\to\mathcal X,\quad\Gamma\phi(x)=y_0+\int_{x_0}^xf(s,\phi(s))ds,\quad\forall x\in I(x_0,\delta)$$By assumptions above $\Gamma$ indeed maps $\mathcal X$ to itself, and further it's a contraction map since $$\begin{align}|(\Gamma\phi_1-\Gamma\phi_2)(x)|&=\left|\int_{x_0}^x(f(s,\phi_1(s))-f(s,\phi_2(s)))ds\right|\\&\le\int_{x_0}^x|f(s,\phi_1(s))-f(s,\phi_2(s))| ds&\text{by triangle inequality}\\&\le L\int_{x_0}^x|\phi_1(s)-\phi_2(s)| ds&\text{by Lipschitz continuity}\\&\le L\int_{x_0}^x\|\phi_1-\phi_2\|_\infty ds\\&\le\delta L\|\phi_1-\phi_2\|_\infty\end{align}$$Now since $\delta L<1$ by definition we can apply the Banach fixed point theorem ([[Metric Space]]) to get that $\Gamma$ has a unique fixed point $\phi\in C(I(x_0,\delta),B(y_0,\delta L))$ satisfying $\Gamma\phi=\phi$, hence is the unique solution to the IVP.
### Optimal interval
In the above theorem the domain of uniqueness obtained is $I(x_0,\delta)$ given $\delta<1/L$, but we can actually improve this result via several different methods when we're given stronger conditions.
- **Iterative application of Picard's theorem**: the Picard's theorem applied on $(x_0,y_0)$ yields the result on $I(x_0,\delta)$, and at this point we can construct a new IVP $$y'=f(x,y),\quad y(x_0+\delta)=y_\delta$$where $y_\delta$ is the boundary value of the solution obtained previously. This expands our interval to $(x_0-\delta, x_0+2\delta)$, and similarly we can repeat the process to extend it to the largest possible domain of definition.
	- **Discussion**: obviously this method requires that $f(x,y)$ is well-defined, and is still Lipschitz continuous in $y$ over sufficiently large domain. 
- **Subtle choice of metric**: we've chosen $\|\cdot\|_\infty$ as the norm to induce a metric, for which the fixed point theorem can be applied. That's actually the key shortcoming of the above proof - we can only extract $\delta$ out of the integral. Instead, if we consider the weighted norm $$\|\phi\|_\alpha=\sup_{x\in I(x_0,\delta)}\left(e^{-\alpha|x-x_0|}|\phi(x)|\right),\quad\alpha>0$$This metric is obviously equivalent to $\|\cdot\|_\infty$, hence also induces a complete normed [[Vector Space]]. Now the pointwise difference becomes $$\begin{align}|(\Gamma\phi_1-\Gamma\phi_2)(x)|&\le\int_{x_0}^x|f(s,\phi_1(s))-f(s,\phi_2(s))|ds\\&\le L\int_{x_0}^x|\phi_1(s)-\phi_2(s)|ds&\text{by Lipschitz continuity}\\&\le L\int_{x_0}^x\|\phi_1-\phi_2\|_\alpha e^{\alpha|s-x_0|}ds&\text{by definition of }\|\cdot\|_\alpha\\&=L\|\phi_1-\phi_2\|_\alpha\cdot\frac{e^{\alpha|x-x_0|}-1}{\alpha}&\text{by direct integration}\end{align}$$hence the corresponding estimation of norm is $$\begin{align}\|\Gamma\phi_1-\Gamma\phi_2\|_\alpha&=\sup_{x\in I(x_0,\delta)}\left(e^{-\alpha|x-x_0|}|(\Gamma\phi_1-\Gamma\phi_2)(x)|\right)\\&\le\frac{L}{\alpha}\|\phi_1-\phi_2\|_\alpha\sup_{x\in I(x_0,\delta)}(1-e^{-\alpha|x-x_0|})&\text{by substitution}\\&=\frac{L}{\alpha}\|\phi_1-\phi_2\|_\alpha\end{align}$$Now the result is obvious: $\alpha>0$ is free to choose, hence we can pick, say, $\alpha=2L$ to conclude that the solution exists and is unique on any interval that makes it well-defined.
	- **When this method fails**: consider the integral equation $$f(x)=\int_0^1\sin(x+f^2(t))dt$$If we use the original Picard-Lindelöf method, then we'll get $$\begin{align}|\Gamma \phi_1-\Gamma\phi_2|(x)&\le\int_0^1|\sin(x+\phi_1^2(t))-\sin(x+\phi_2^2(t))|dt\\&\le\int_0^1|\phi_1-\phi_2|\cdot|\phi_1+\phi_2|dt\\&\le2\int_0^1|\phi_1-\phi_2|dt\end{align}$$and obviously this would fail. If we use instead the revised metric above, then by some simple calculation we finally get $$\|\Gamma\phi_1-\Gamma\phi_2\|\le2\|\phi_1-\phi_2\|\frac{e^{\alpha}-1}{\alpha}\sup_{x\in[0,1]}e^{-\alpha x}=2\frac{e^{\alpha}-1}{\alpha}\|\phi_1-\phi_2\|$$and this fails again. The problem is that, in the above integral equation the domain of integration is fixed, hence the resulting coefficient in the upper bound for $|\Gamma\phi_1-\Gamma\phi_2|$ does not contain $x$, and is too large for $e^{-\alpha x}$ to control. To solve this problem we first notice that by direct expanding the trigonometric functions we get $$f(x)=\sin x\int_0^1\cos f^2(t)dt+\cos x\int_0^1\sin f^2(t)dt$$hence we expect that the solution is $f(x)=\alpha\sin x+\beta\cos x$ where $\alpha,\beta$ should satisfy $$(\alpha,\beta)=\left(\int_0^1\cos(\alpha\sin t+\beta\cos t)^2dt,\int_0^1\sin(\alpha\sin t+\beta\cos t)^2dt\right)$$We define a map $\Gamma:B_2\to B_2$ where $B_2\subset\mathbb R^2$ the unit ball that maps LHS to RHS, then by the Brouwer fixed point theorem we know that the desired $(\alpha,\beta)$ exists.

## First order difference equations
Equations of the form $$y_{n+1}=f(n,y_n)$$are called **first order difference equations**. It is the **discrete case** of differential equations, and its linearity, non-linearity and other classification are the same as differential equations. 
- Logistic difference equations: consider $u_{n+1}=\rho u_n(1-u_n)$.
	- As $\rho$ increase continuously, the period of stable state splits into $2, 4,8,\cdots$. these $\rho$ are called **bifurcations**.
	- For greater $\rho$ the sequence goes into chaos. [[Complexity A Guided Tour]]