Given an IVP the set $\set{(x_i,y_i)}$ with $h_i=x_{i+1}-x_i$ the **step size** and $y_i\approx y(x_i)$ the approximate value for the equation is called a **numerical solution**. We assume the existence and uniqueness of solution, and pick $h_i\equiv h,x_i=a+ih$.
- **Order of a method**: if th local error (see below) satisfies $Ry=O(h^{p+1})$ then we say that the method has order of precision $p$.
## First order ODE
Consider the equation ([[First Order ODE]]) $$\begin{cases}y'(x)=f(x,y(x)),&a\le x\le b\\ y(a)=y_0\end{cases}$$Define the **local error** as $Ry=y(x_{i+1})-y_{i+1}$, with the local assumptions that $y_i=y(x_i)$ for all previous points. 
- **Euler's method**: replace $y'$ by [[Numerical Differentiation]] and discard the error term to get $$y_{i+1}=y_i+hf(x_i,y_i)$$It's easy to deduce that $Ry=\frac{h^2}{2}y''(\xi_i),\xi_i\in[x_i,x_{i+1}]$.
	- **Backward Euler's method**: if the replacement happen at $x_{i+1}$ we get $$y_{i+1}=y_i+hf(x_{i+1},y_{i+1}),\quad Ry=-\frac{h^2}{2}y'''(\xi_i)$$We can solve $y_{i+1}=g(x_i,x_{i+1},y_i)$ from this equation. This is usually down by [[Solving Non-linear System]].
	- **Method of middle point**: if we take $y'(x)=\frac{y(x+h)-y(x-h)}{2h}-\frac{h^2}{6}y'''(\xi_i)$ we get $$y_{i+1}=y_{i-1}+2hf(x_i,y_i),\quad Ry=-\frac{h^3}{6}y'''(\xi_i)$$
	- **Modified Euler's method**: instead of solely relying on Euler's method we let $$\begin{cases}y_{i+1}^{(0)}=y_i+hf(x_i,y_i)\\y_{i+1}=y_i+\frac{h}{2}(f(x_i,y_i)+f(x_{i+1},y_{i+1}^{(0)}))\end{cases}$$The result is more precise. We call such method the **predictor-corrector method**.
- **Method of numerical integration**: integrating both sides yields $$y(x_{i+1})-y(x_i)=\int_{x_i}^{x_{i+1}}f(x,y(x))dx$$hence [[Numerical Integration]] can be applied to calculate $y_{i+1}=y_i+\mathcal If(x,y(x))$.
	- Using this method we can also find the corresponding version of (backward) Euler's method and method of middle point.
- **Adams-Bashforth formula**: given $(x_{i-j},y_{i-j}),0\le j\le k$ we can construct a [[Polynomial Interpolation]] polynomial $f=L+R$, and integrate both sides to get $$y(x_{i+1})-y(x_i)=\int_{x_i}^{x_{i+1}}y'(x)=\int_{x_i}^{x_{i+1}}(L_k+R_k)dx\approx \int_{x_i}^{x_{i+1}}L_kdx$$the integration can be performed numerically or analytically.
- **Method of Taylor series**: we can directly use Taylor series to approximate the recursion between $y_{i+1}$ and $y_i$. Note that higher derivatives should be calculated using partial derivatives. We have $Ry=\frac{h^{p+1}}{(p+1)!}y^{(p+1)}(\xi_i)$.
## Runge-Kutta method
The general formula for Runge-Kutta method is $$\begin{align}y_{n+1}&=y_n+h\sum_{i=1}^sb_ik_i,\\ k_1 & = f(t_n, y_n)\\
 k_2 & = f(t_n+c_2h, y_n+(a_{21}k_1)h) \\k_3 & = f(t_n+c_3h, y_n+(a_{31}k_1+a_{32}k_2)h)\\& \ \ \vdots \\ k_s & = f(t_n+c_sh, y_n (a_{s1}k_1+a_{s2}k_2+\cdots+a_{s,s-1}k_{s-1})h)\end{align}$$where $s,a_{ij},b_i,c_i$ are predefined coefficients, usually listed by the **Butcher table** $$\begin{array}{c|ccccc}0\\ c_2&a_{21}\\ c_3&a_{31}&a_{32}\\\vdots&\vdots&&\ddots\\ c_s&a_{s1}&a_{s2}&\cdots& a_{s,s-1}\\\hline &b_1&b_2&\cdots&b_{s-1}&b_s\end{array}$$To determined the value of these coefficients we usually require the highest possible order of $O(Ry)=O(y(x_{i+1})-y_i)$. A commonly used condition is $$\sum_{i=1}^sb_i=1,\quad\sum_{j=1}^{i-1}a_{ij}=c_i,\quad\forall i=2,\cdots,s$$Note that these conditions along is neither sufficient nor necessary for consistency.
 - **Discussion**: RH method is essentially a general template of [[Iterative Method]] for solving first order ODE. It's obvious that previously mentioned expressions can be recovered from RK formula by picking proper coefficients.
 - **Accuracy**: we compare the method to forward/backward Euler formula to illustrate why it's usually of higher accuracy. By considering the usual pendulum problem it's obvious that forward/backward Euler would lead to energy increasing/decreasing, and this is mainly due to **alternating [[Convexity]]/concavity** of $\sin x$. In contract, the classical RK4 remedies this by iteratively calculating the slopes at several points, and cancelling the amplifying/suppressing effects out via weighted average.
## Other methods
- **Method of undetermined coefficients**: given a multi-step linear formula $$y_{i+1}=\sum_{k=0}^k\alpha_jy_{i-j}+h\sum_{j=-1}^k\beta_k f_{i-j},\quad Ry=y(x_{i+1})-\sum_{j=0}^k\alpha_jy(x_{i-j})-h\sum_{j=-1}^k\beta_jy'(x_{i-j})$$we requires that $Rx^s=0$ for as many $s$ as possible to determine the coefficients.
## System of first order ODE
Any higher order ODE can be transformed into a system of first order ODE, hence it suffices to focus on numerical solution of such system. Note that all above methods can be applied directly in this case without modification.
- **Runge-Kutta method**: the general form is the same, except that all functions are now vectors. A typical R-K method of order 4 is $$\begin{cases}y_{i+1}=y_i+\frac{1}{6}(K_1+2K_2+2K_3+K_4)\\ K_1=hf(x_i,y_i)\\ K_2=hf(x_i+\frac{h}{2},y_i+\frac{1}{2}K_1)\\ K_3=hf(x_i+\frac{h}{2},y_i+\frac{1}{2}K_2)\\ K_4=hf(x_i+h,y_i+K_3)\end{cases}$$Note that each of the symbols are vectors.