Many different approximations can be used for numerical integration, such as step functions (Riemann sum), polynomial [[Polynomial Interpolation]], polygonal approximation, etc.. The key idea is to find a proper decomposition $f=g+R$ on $[a,b]$ and take $$\mathcal If=\mathcal Ig+\mathcal IR\approx\mathcal Ig$$where $\mathcal Ig$ is easy to obtain while $R$ is small.
## Newton-Cotes formula
Consider the Lagrange polynomial [[Polynomial Interpolation]] of $f$ of the form $$f(x)=L_n(x)+R_n(x)=\sum_{i=0}^nf(x_i)l_i(x)+\frac{f^{(n+1)}(\xi)}{(n+1)!}(x-x_0)\cdots(x-x_n)$$given $a=x_0<x_1<\cdots<x_n=b$, we call $\mathcal If\approx\mathcal IL_n$ the (closed) **Newton-Cotes formula**, with remainder term $\mathcal IR_n$. In general we have the form $$\mathcal Ig=\sum A_if(x_i)$$We call these $A_i$ the **quadrature coefficients**. It's obvious that the problem now amounts to finding proper $A_i$. Below we'll take $x_{i+1}-x_i\equiv h$ and try different $n$.
- **Trapezoidal rule ($n=1$)**: we choose the connecting $(a,f(a)),(b,f(b))$, then $$\mathcal IL_1=\frac{b-a}{2}(f(a)+f(b)),\quad\mathcal IR_1=\int_a^b\frac{f''(\xi)}{2!}(x-a)(x-b)dx=-\frac{(b-a)^3}{12}f''(\eta)$$for some $\eta\in[a,b]$. The estimation for remainder term used the generalized mean value theorem, taking $\xi=\xi(x)$ ([[Integral Calculus on Euclidean Space]]).
- **Simpson's rule ($n=2$)**: with some calculation we have $$\mathcal IL_2=\frac{b-a}{6}\left(f(a)+4f\left(\frac{a+b}{2}\right)+f(b)\right),\quad\mathcal IR_2=-\frac{(b-a)^5}{2880}f^{(4)}(\eta)$$
- **Cotes's rule ($n=4$)**: similarly, we have $$\mathcal IL_4=\frac{b-a}{90}(7f(a)+32f(x_1)+12f(x_2)+32 f(x_3)+7f(b)),\quad\mathcal IR_4=-\frac{(b-a)^7}{1935360}f^{(6)}(\eta)$$the expression of $\mathcal IR_2$ is calculated via the expression of $R_2$.
- **Composite quadrature rule**: due to the Runge's phenomenon ([[Polynomial Interpolation]]) increasing $n$ doesn't improve the precision of integration a lot. To this end we consider to partition $[a,b]$ into several equi-length sub-intervals, and apply numerical quadrature on each one of them.
	- **Composite trapezoidal rule**: with $n$ subintervals of equal length $h=\frac{b-a}{n}$, we have $$\mathcal IL_{1,n} = \frac{h}{2} \left(f(a) + 2\sum_{i=1}^{n-1} f(x_i) + f(b)\right),\quad \mathcal IR_{1,n} = -\frac{(b-a)h^2}{12}f''(\eta)$$
	- **Composite Simpson's rule ($2\mid n$)**: with $n$ even and $h=\frac{b-a}{n}$, we have $$\mathcal IL_{2,n} = \frac{h}{3} \left(f(a) + 4\sum_{2\not\mid i} f(x_i) + 2\sum_{2\mid i}^{n-2} f(x_i) + f(b)\right),\quad \mathcal IR_{2,n} = -\frac{(b-a)h^4}{180}f^{(4)}(\eta)$$
	- **Composite Cotes's rule ($4\mid n$)**: with $n=4m$ and $h=\frac{b-a}{n}$, we have $$\begin{align}&\mathcal IL_{4.n} = \frac{2h}{45} \sum_{j=0}^{m-1} \left(7f(x_{4j}) + 32f(x_{4j+1}) + 12f(x_{4j+2}) + 32f(x_{4j+3}) + 7f(x_{4j+4})\right)\\&\mathcal IR_{4,n} = -\frac{(b-a)h^6}{9450}f^{(6)}(\eta)\end{align}$$
- **Romberg's method**: instead of a prescribed set of points, we start with some composite rule, and increase the number of interpolation points by separating each sub-interval from the middle in each step. Take composite trapezoidal rule for example, we initially have $\mathcal IR_{1,n}=-\frac{(b-a)h^2}{12}f''(\eta)$, in the second step we have $n\to 2n,h\to h/2$, hence $$\mathcal I R_{1,2n}=\frac{1}{4}\mathcal IR_{1,n}$$by letting $n\to\infty$ we can get arbitrary precision. Also, the results in $\mathcal IL_{1,n}$ can be utilized in $\mathcal IL_{1,2n}$ in the following way: $$\begin{align}\mathcal IL_{1,2n}&=\frac{h}{4}\left(f(a)+2\sum_{i=1}^{n-1}f(x_i)+2\sum_{i=1}^nf\left(\frac{x_{i-1}+x_i}{2}\right)+f(b)\right)\\&=\frac{1}{2}\mathcal IL_{1,n}+\frac{h}{2}\sum_{i=1}^n f\left(\frac{x_{i-1}+x_i}{2}\right)\end{align}$$this simplifies the calculation further.
	- **Iterative calculation**: denote the $\mathcal IL_{1,n},\mathcal IL_{2,n},\mathcal IL_{4,n}$ as $T_n,S_n,C_n$, then notice $$\begin{cases}S_{2^k}=T_{2^{k+1}}+\frac{1}{4-1}(T_{2^{k+1}}-T_{2^k})\\ C_{2^k}=S_{2^{k+1}}+\frac{1}{4^2-1}(S_{2^{k+1}}-S_{2^k})\\ R_{2^k}=C_{2^{k+1}}+\frac{1}{4^3-1}(C_{2^{k+1}}-C_{2^k})\end{cases}$$In general we'll first calculate all $T_n$ and progressively obtain $S,C,R$ in the proper order.
## Method of undetermined coefficients
Some $\mathcal Ig\approx\mathcal If$ is said to have **algebraic precision** $m$ if $\mathcal IR[f]=0$ for any polynomial $\deg f\le m$. In the general form $\mathcal Ig=\sum A_if(x_i)+\cdots$ one way to find proper $A_i$ is to let it has algebraic precision $m$, i.e., it should satisfy the linear system $$\mathcal IR[x^k]=\mathcal Ix^k-\sum A_ix_i^k-\cdots=0,\quad\forall 0\le k\le m$$We call it the **method of undetermined coefficients**.
- **Error estimation**: if $\mathcal IR$ is a linear functional on $C^{m+1}([a,b])$, and the algebraic precision of $f\mapsto\mathcal I g$ is $m$, then for arbitrary set of points $\tilde x_i\in[a,b]$ there exists $\xi=\xi(x,\tilde x_0,\cdots,\tilde x_n)$ lying between $\tilde x_i$. we have $$\mathcal IR[f]=\mathcal IR[e],\quad e(x)=\frac{f^{(m+1)}(\xi)}{(m+1)!}(x-\tilde x_0)(x-\tilde x_1)\cdots(x-\tilde x_m)$$**Proof**: the crux that $\tilde x_i$ can be chosen arbitrarily lies in the algebraic precision of $f\mapsto\mathcal Ig$. Given any set of interpolating point $\tilde x_i$ we have $f=p_n+e$ where $\deg p\le n$, hence $$\mathcal IRf=\mathcal IR(f+e)=\mathcal IRe$$where $e=e(x)$ is exactly the above expression.
	- **Choice of $\tilde x_i$**: for easier calculation we should ensure that $\prod(x-\tilde x_i)$ doesn't change sign (so that generalized mean value theorem for integral ([[Integral Calculus on Euclidean Space]]) can be applied to simplify calculation) and $\tilde x_i$ takes on least number of different values.
- **Peano kernel theorem**: given $V\subset\bv([a,b])$ containing differentiable functions and $L\in V^*$ s.t. $Lp=0,\forall p\in\mathbb P_n$, and suppose further that for any $g(x,t)$ with $g(x,\cdot),g(\cdot,t)\in C^{n+1}$ we have $$L\int_a^b g(x,t)dt=\int_a^b Lg(x,t)dt$$and define the **Peano kernel** of $L$ as $$K(t)=\frac{1}{n!}L(x-t)_+^n,\quad(x-t)_+^n=\begin{cases}(x-t)^n,& x\ge t\\0,& x<t\end{cases}$$then given $k\in V$ for any $f\in C^{n+1}$ we have $$Lf=\int_a^bK(t)f^{(n+1)}(t)dt$$**Proof**: by Taylor series with integral remainder ([[Differential Calculus on Euclidean Space]]) $$f(x)=\sum_{k=0}^n\frac{f^{(k)}(a)}{k!}(x-a)^k+\frac{1}{n!}\int_a^x(x-t)^nf^{(n+1)}(t)dt$$Apply $L$ on both sides, and utilize the fact that $L\mathbb P_n=0$ and interchangeability with integral: $$\begin{align}Lf&=L\left(\frac{1}{n!}\int_a^x(x-t)^nf^{(n+1)}(t)dt\right)\\&=L\left(\frac{1}{n!}\int_a^b(x-t)_+^nf^{(n+1)}(t)dt\right)\\&=\int_a^b\left(\frac{1}{n!}L(x-t)_+^n\right)f^{(n+1)}(t)dt\\&=\int_a^bK(t)f^{(n+1)}(t)dt\end{align}$$This complete the proof.
	- **Generalization to the result above**: this is similar to how Taylor series is generalized to [[Polynomial Interpolation]]. Peano kernel theorem only consider the Taylor series (which is local), while in numerical integration (and actually many other aspects) we used the interpolation polynomial (which is global). Despite such difference their essence are the same: utilize the annihilation property to simplify the expression.
		- **Even further generalization**: the theorem actually generalize to a lot wider range of numerical fields, such as [[Numerical Differentiation]]. The key is that, as long as the numerical scheme annihilates $\mathbb P_n$ the above theorem can be applied.
		- **Taylor expansion of [[Dual Space]]**: the above generalization can be perceived under a more general framework. Given a list of $L_n$ s.t. $L_n\mathbb P_n=0$ we may consider to decompose $L$ into $L=\sum\alpha_nL_n$,
	- **Bounds**: by HÃ¶lder's inequality ([[Lp Space]]) we have $$|Lf|\le\|K\|_p\|f^{(n+1)}\|_q,\quad\forall1\le p,q\le\infty,\frac{1}{P}+\frac{1}{q}=1$$In the error estimation above we actually used $p=1,q=\infty$.
	- **Example**: for trapezoidal rule following the above process the Peano kernel is $$K(t)=\frac{(b-t)(t-a)}{2}$$This fits in the fact that we can take $\tilde x_0=a,\tilde x_1=b$, and actually provide a more general and direct method for error estimation.
	- **Interpretation of kernel**: notice that $K$ actually describes the relation between $f^{(n+1)}$ and a specific quadrature rule $L$ that annihilates $\mathbb P_n$.
## Gaussian quadrature
Now consider the general Newton-Cotes formula with quadrature coefficients $A_i,0\le i\le n$. Obviously the algebraic precision $m\ge n$, while if we choose $$f(x)=\prod(x-x_i)^2\quad\Longrightarrow\quad\mathcal If=\int_a^bf(x)dx>0,\quad\mathcal Ig=\sum A_if(x_i)=0$$hence $\mathcal IRf\neq0$, which means $m\le 2n+1$. Notice that if $A_i,x_i$ are chosen s.t. $$\mathcal Ix^k=\sum_{i=0}^n A_ix_i^k,\quad\forall 0\le k\le 2n+1$$then we'll have $m=n$, i.e., it achieves the highest algebraic precision. We call such quadrature rule $\mathcal I_G$ a **Gaussian quadrature**.
- **Peano kernel**: by results above the error of Gaussian quadrature is given by $$\mathcal I_GRf=\frac{f^{(2n)}(\xi)}{(2n)!}\int_a^b\prod(x-x_i)^2dx$$hence the Peano kernel of $\mathcal I_G$ is $$K(x)=\prod(x-x_i)^2$$